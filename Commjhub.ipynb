{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "757d40bd-8a85-4934-bec3-e2d8d169343d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697.24s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -angchain (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: nomic in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (3.0.25)\n",
      "Requirement already satisfied: click in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic) (8.1.6)\n",
      "Requirement already satisfied: jsonlines in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from nomic) (4.0.0)\n",
      "Requirement already satisfied: loguru in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from nomic) (0.7.2)\n",
      "Requirement already satisfied: rich in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic) (13.5.2)\n",
      "Requirement already satisfied: requests in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic) (2.28.1)\n",
      "Requirement already satisfied: numpy in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from nomic) (1.24.4)\n",
      "Requirement already satisfied: pandas in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic) (1.2.4)\n",
      "Requirement already satisfied: pydantic in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from nomic) (2.7.1)\n",
      "Requirement already satisfied: tqdm in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from nomic) (4.66.2)\n",
      "Requirement already satisfied: pyarrow in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from nomic) (16.0.0)\n",
      "Requirement already satisfied: pillow in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic) (8.2.0)\n",
      "Requirement already satisfied: pyjwt in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from nomic) (2.8.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from jsonlines->nomic) (23.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from pandas->nomic) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from pandas->nomic) (2021.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from pydantic->nomic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from pydantic->nomic) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from pydantic->nomic) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests->nomic) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests->nomic) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests->nomic) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests->nomic) (2023.7.22)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from rich->nomic) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from rich->nomic) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich->nomic) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->nomic) (1.15.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -angchain (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#Run this if you are running the program for the first time\n",
    "!pip install nomic\n",
    "!pip install -U langchain-nomic langchain_community tiktoken langchain-openai chromadb langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4a5e3f9-b03a-4eea-9930-31beedacb709",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_nomic.embeddings import NomicEmbeddings\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f5fb6990-137f-4880-bc5e-fc61016fbcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data into text functions\n",
    "\n",
    "import os\n",
    "\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_nomic import NomicEmbeddings\n",
    "from langchain_nomic.embeddings import NomicEmbeddings\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "pdf_list = [\"Style.pdf\", \"DEI.pdf\", \"34th.pdf\", \"sports.pdf\"]\n",
    "urls = [\n",
    "'https://yoast.com/slug/', 'https://www.semrush.com/blog/what-is-a-url-slug/?kw=&cmp=US_SRCH_DSA_Blog_EN&label=dsa_pagefeed&Network=g&Device=c&kwid=dsa-2185834088336&cmpid=18348486859&agpid=156019556762&BU=Core&extid=97592280163&adpos=', 'https://www.upwork.com/resources/how-to-write-seo-content','https://authorservices.wiley.com/author-resources/Journal-Authors/Prepare/writing-for-seo.html','https://www.semrush.com/blog/seo-writing/','https://www.semrush.com/kb/839-how-to-write-seo-articles-four-steps','https://www.flowmatters.com/blog/a-practical-guide-on-how-to-write-seo-articles/','https://www.maropost.com/how-to-combine-seo-and-email-marketing-for-better-rankings/','https://www.webfx.com/seo/learn/email-marketing-tips-to-improve-seo/','https://sendgrid.com/en-us/blog/seo-and-email-marketing','https://www.emailonacid.com/blog/article/email-marketing/seo-connections/','https://coalitiontechnologies.com/blog/strategic-seo-tips-for-email-marketing','https://optinmonster.com/101-email-subject-lines-your-subscribers-cant-resist/','https://www.wordstream.com/blog/ws/2014/03/31/email-subject-lines','https://www.constantcontact.com/blog/good-email-subject-lines/','https://blog.hubspot.com/marketing/best-email-subject-lines-list'\n",
    "]\n",
    "\n",
    "def load_csv(csv):\n",
    "    loader = CSVLoader(file_path= csv)\n",
    "    data = loader.load()\n",
    "    return data\n",
    "\n",
    "def load_url(url_list):\n",
    "    urls = url_list\n",
    "    docs = [WebBaseLoader(url).load() for url in urls]\n",
    "    docs_list = [item for sublist in docs for item in sublist]\n",
    "    return docs_list\n",
    "\n",
    "def load_pdf(pdf_list):\n",
    "    pdfs = pdf_list\n",
    "    output = [PyPDFLoader(pdf).load() for pdf in pdfs]\n",
    "    pdfs_list = [item for sublist in output for item in sublist]\n",
    "    return pdfs_list\n",
    "\n",
    "data = load_csv(\"merged_stats.csv\")\n",
    "docs_list = load_url(urls)\n",
    "pdfs_list = load_pdf(pdf_list)\n",
    "\n",
    "#Splitting\n",
    "def splitter(data, docs_list, pdfs_list):\n",
    "    text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=7500, chunk_overlap=100\n",
    "    )\n",
    "    \n",
    "    doc_splits = text_splitter.split_documents(data)\n",
    "    \n",
    "    url_text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=7500, chunk_overlap=100\n",
    "    )\n",
    "    \n",
    "    url_splits = url_text_splitter.split_documents(docs_list)\n",
    "    \n",
    "    pdf_text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=7500, chunk_overlap=100\n",
    "    )\n",
    "    \n",
    "    pdf_splits = pdf_text_splitter.split_documents(pdfs_list)\n",
    "\n",
    "    return doc_splits, url_splits, pdf_splits\n",
    "\n",
    "doc_splits, url_splits, pdf_splits = splitter(data, docs_list, pdfs_list) \n",
    "\n",
    "# Vector DB for Articles.csv\n",
    "csv_vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1\"),\n",
    ")\n",
    "csv_retriever = csv_vectorstore.as_retriever()\n",
    "\n",
    "# Vector DB for SEO \n",
    "\n",
    "url_vectorstore = Chroma.from_documents(\n",
    "    documents=url_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1\"),\n",
    ")\n",
    "url_retriever = url_vectorstore.as_retriever()\n",
    "\n",
    "# Vector DB for Writing Style Documents \n",
    "\n",
    "pdf_vectorstore = Chroma.from_documents(\n",
    "    documents=pdf_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1\"),\n",
    ")\n",
    "pdf_retriever = pdf_vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\" Pretend you are an SEO expert for a company called \"The Daily Pennsylvanian\" that does journalism for the University of Pennsylvania.  \n",
    "Answer the question based only on the following context: \n",
    "\n",
    "Information about previous articles as well as their performance metrics can be found through: {context}\n",
    "\n",
    "Information about SEO Optimization can be found through: {context1}\n",
    "\n",
    "The Daily Pennsylvanian writing style guide and tips can be found through: {context2}\n",
    "\n",
    "Question: Output 3 potential URL Slugs and SEO titles based on the provided Drafted Title and Content \n",
    "make sure that the URL Slug is in the correct format that a URL Slug should be and that \n",
    "the SEO title is search engine optimized and concise. DO NOT ASSUME ANY INFORMATION, make the title based ONLY on the information told in the question {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Local LLM\n",
    "ollama_llm = \"llama3\"\n",
    "model_local = ChatOllama(model=ollama_llm)\n",
    "\n",
    "# Chain\n",
    "# take the question, chroma search, gives back chunks, that \n",
    "# context , 1 , 2 , 3 seperate objects retrievers\n",
    "chain = (\n",
    "    {\"context\": csv_retriever, \"context1\" : url_retriever, \"context2\" : pdf_retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model_local\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4435fbb4-a80a-43bb-bd0d-b728befeef65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please give me your suggested title, I will optimize it!  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please tell me what you are writing about:  They say that when you get worked up about something to count down from ten or repeat a mantra to try to calm down. But what happens when your chest gets so tight that you can’t think about what comes after seven? What about when you stomach is lurching up your throat at what feels like 1,000 miles an hour? How are you supposed to remember a mantra when you are trying to stop your eyes from darting from right to left, constantly in search of something but you’re not sure what, all while you are trying to figure out how to escape your shirt that is inexplicably and suddenly trying to pull you inside out?  I had my first panic attack when I was 17. I was sitting in my AP Stat class, third row back, fourth seat from the right. It was a crisp early October day and I remember the vivid fall colors adorning the trees outside the windows to my right: burnt orange leaves with the veins dyed deeper orange hues, blood red, perfectly symmetrical foliage interspersed with faded green stragglers — the colors you’d associate with a picturesque fall day in Princeton, New Jersey.   My teacher was coming around to check homework — homework that I obviously had not done despite being up all night the night before. I was trying to come up with an excuse as to why I didn’t have it today. Maybe I left it in my locker. Maybe I’d rifle through my backpack and tell her to come back to me later and hope she forgot.   The closer she got, however, the more it felt like I was being pulled back into my head; like my consciousness was getting further and further from my eyes. In the next moments, I felt my chest get tight and I started to sweat profusely. I didn’t know what was happening but I could not stop thinking about how the girl sitting next to me smelled so strongly of cigarettes it was burning my brain. My breaths got shorter and shorter and shorter until I felt like I was breathing in a coffin. I got up from my seat and, without any explanation, rushed as calmly as I could — which was not very calmly at all — to the nearest bathroom, locked the door of the first stall behind me, and threw up.   After a few minutes, I took the shirt I had brought for football practice later that day and tried to get as much of the sweat off of me as I could to little avail; it was like I had stepped into a shower that was too cold and quickly bounced out to wait for it to heat but got wet nonetheless. When I did as much as I could to clean myself up, I walked back into the classroom, tightly strolled to my seat in the third row, fourth seat from the right, next to the girl who smoked too many cigarettes and started taking notes. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response\n",
      "Based on the provided content, here are three potential URL Slugs and SEO titles:\n",
      "\n",
      "**Option 1:**\n",
      "URL Slug: penn-williams-hall-uncomfortable-classroom-temperatures\n",
      "SEO Title: \"Uncomfortable Classroom Temperatures: Williams Hall Students Face Heat Wave\"\n",
      "\n",
      "**Option 2:**\n",
      "URL Slug: overheated-classrooms-disrupt-penn-learning\n",
      "SEO Title: \"Overheated Classrooms Disrupt Learning at Penn: Williams Hall's Temperature Issues Cause Concern\"\n",
      "\n",
      "**Option 3:**\n",
      "URL Slug: penn-williams-hall-classroom-temperature-issues\n",
      "SEO Title: \"Temperature Issues in Williams Hall Classrooms Cause Concern for Students and Faculty at Penn\"\n",
      "\n",
      "These options aim to capture the essence of the article, highlighting the uncomfortable temperatures in Williams Hall classrooms and their impact on students' learning experiences. The URL Slugs follow the standard format of including relevant keywords and being concise.\n"
     ]
    }
   ],
   "source": [
    "def activate_chain(t, c):\n",
    "    output = chain.invoke(f'Title: {t} and Content: {c}')\n",
    "    return output\n",
    "    \n",
    "title = (str(input(\"Please give me your suggested title, I will optimize it! \")))\n",
    "print()\n",
    "content = str(input(\"Please tell me what you are writing about: \"))\n",
    "\n",
    "print(\"response\")\n",
    "print(activate_chain(title, content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ad03c15-12cd-4f9e-8b4b-8e6647046248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Load the environment variables and setup (same as before)\n",
    "load_dotenv()\n",
    "model = os.getenv(\"MODEL_NAME\", \"llama3:latest\")\n",
    "\n",
    "# Define the RAG chain setup here (as per your previous code)\n",
    "# Assuming all imports and setup from your RAG code are done correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e9e014-f588-471c-873a-80db5cf1696c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 4.16.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n",
      "Running on local URL:  http://127.0.0.1:7865\n",
      "Running on public URL: https://6f6b5facaefe3b92aa.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://6f6b5facaefe3b92aa.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/anaconda3/share/jupyter/venv/py3-11_comm4190/lib/python3.11/site-packages/gradio/queueing.py\", line 495, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/anaconda3/share/jupyter/venv/py3-11_comm4190/lib/python3.11/site-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/anaconda3/share/jupyter/venv/py3-11_comm4190/lib/python3.11/site-packages/gradio/blocks.py\", line 1561, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/anaconda3/share/jupyter/venv/py3-11_comm4190/lib/python3.11/site-packages/gradio/blocks.py\", line 1179, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/anaconda3/share/jupyter/venv/py3-11_comm4190/lib/python3.11/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/anaconda3/share/jupyter/venv/py3-11_comm4190/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 2134, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/usr/local/anaconda3/share/jupyter/venv/py3-11_comm4190/lib/python3.11/site-packages/anyio/_backends/_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/anaconda3/share/jupyter/venv/py3-11_comm4190/lib/python3.11/site-packages/gradio/utils.py\", line 695, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_2811589/3310146750.py\", line 8, in chat\n",
      "    chat_history.append((input_text, chain.invoke(prompt_text)))\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/anaconda3/share/jupyter/venv/py3-11_comm4190/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 2499, in invoke\n",
      "    input = step.invoke(\n",
      "            ^^^^^^^^^^^^\n",
      "  File \"/usr/local/anaconda3/share/jupyter/venv/py3-11_comm4190/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 158, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/usr/local/anaconda3/share/jupyter/venv/py3-11_comm4190/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 560, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/anaconda3/share/jupyter/venv/py3-11_comm4190/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 421, in generate\n",
      "    raise e\n",
      "  File \"/usr/local/anaconda3/share/jupyter/venv/py3-11_comm4190/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 411, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/usr/local/anaconda3/share/jupyter/venv/py3-11_comm4190/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 632, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/anaconda3/share/jupyter/venv/py3-11_comm4190/lib/python3.11/site-packages/langchain_community/chat_models/ollama.py\", line 259, in _generate\n",
      "    final_chunk = self._chat_stream_with_aggregation(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/anaconda3/share/jupyter/venv/py3-11_comm4190/lib/python3.11/site-packages/langchain_community/chat_models/ollama.py\", line 190, in _chat_stream_with_aggregation\n",
      "    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):\n",
      "  File \"/usr/local/anaconda3/share/jupyter/venv/py3-11_comm4190/lib/python3.11/site-packages/langchain_community/chat_models/ollama.py\", line 162, in _create_chat_stream\n",
      "    yield from self._create_stream(\n",
      "               ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/anaconda3/share/jupyter/venv/py3-11_comm4190/lib/python3.11/site-packages/langchain_community/llms/ollama.py\", line 246, in _create_stream\n",
      "    raise OllamaEndpointNotFoundError(\n",
      "langchain_community.llms.ollama.OllamaEndpointNotFoundError: Ollama call failed with status code 404. Maybe your model is not found and you should pull the model with `ollama pull llama3`.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def chat(input_text, dept, title, content, chat_history):\n",
    "    chat_history = chat_history or []\n",
    "    global context\n",
    "    \n",
    "    # Assemble the prompt text if necessary\n",
    "    prompt_text = f\"Given that I work for this department {dept} and have the article title of this: {title}, here is what the article is about {content} answer this question: {input_text}\"\n",
    "    \n",
    "    chat_history.append((input_text, chain.invoke(prompt_text)))\n",
    "    \n",
    "    # Clear input fields and maintain the chat history\n",
    "    return chat_history, chat_history, \"\", \"\", \"\", \"\"\n",
    "\n",
    "# Adjust the chain setup\n",
    "chain = (\n",
    "    {\"context\": csv_retriever, \"context1\": url_retriever, \"context2\": pdf_retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model_local\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Setup Gradio UI\n",
    "theme = gr.themes.Base(\n",
    "    primary_hue=\"red\",\n",
    "    secondary_hue=\"red\",\n",
    "    neutral_hue=\"slate\",\n",
    ")\n",
    "\n",
    "with gr.Blocks(theme=theme) as demo:\n",
    "    gr.Markdown(\"<h1><center>Daily Pennsylvanian SEO Optimizer</center></h1>\")\n",
    "    chatbot = gr.Chatbot()\n",
    "    title = gr.Textbox(placeholder=\"Title here\", label=\"Article Title\")\n",
    "    content = gr.Textbox(placeholder=\"Article content here\", label=\"Article Content\")\n",
    "    input_box = gr.Textbox(placeholder=\"Chat with the GPT\", label=\"Question\")\n",
    "    dept = gr.Dropdown([\"Under the Button\", \"34th Street\", \"Quaker Nation\", \"DP General\"], label=\"Department\", info=\"Please tell me what department you are writing for!\", allow_custom_value = True)\n",
    "    state = gr.State()\n",
    "\n",
    "    submit = gr.Button(\"SEND\")\n",
    "    clear = gr.Button(\"CLEAR\")\n",
    "    reset_chat = gr.Button(\"RESET CHAT HISTORY\")\n",
    "\n",
    "    submit.click(chat, inputs=[input_box, dept, title, content, state], outputs=[chatbot, state, input_box, dept, title, content])\n",
    "    clear.click(lambda: ([], None, None, None, [], []), inputs=None, outputs=[chatbot, input_box, dept, title, content, state], queue=False)\n",
    "    reset_chat.click(lambda: ([]), inputs=None, outputs=[chatbot], queue=False)\n",
    "\n",
    "demo.launch(debug=True, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43640ec-8842-4115-a07c-7356fcffdc83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3.11 (COMM4190)",
   "language": "python",
   "name": "comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
