{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "757d40bd-8a85-4934-bec3-e2d8d169343d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -angchain (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: nomic in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (3.0.25)\n",
      "Requirement already satisfied: click in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic) (8.1.6)\n",
      "Requirement already satisfied: jsonlines in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from nomic) (4.0.0)\n",
      "Requirement already satisfied: loguru in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from nomic) (0.7.2)\n",
      "Requirement already satisfied: rich in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic) (13.5.2)\n",
      "Requirement already satisfied: requests in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic) (2.28.1)\n",
      "Requirement already satisfied: numpy in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from nomic) (1.24.4)\n",
      "Requirement already satisfied: pandas in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic) (1.2.4)\n",
      "Requirement already satisfied: pydantic in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from nomic) (2.7.1)\n",
      "Requirement already satisfied: tqdm in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from nomic) (4.66.2)\n",
      "Requirement already satisfied: pyarrow in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from nomic) (16.0.0)\n",
      "Requirement already satisfied: pillow in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic) (8.2.0)\n",
      "Requirement already satisfied: pyjwt in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from nomic) (2.8.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from jsonlines->nomic) (23.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from pandas->nomic) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from pandas->nomic) (2021.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from pydantic->nomic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from pydantic->nomic) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from pydantic->nomic) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests->nomic) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests->nomic) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests->nomic) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests->nomic) (2023.7.22)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from rich->nomic) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from rich->nomic) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich->nomic) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->nomic) (1.15.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -angchain (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -angchain (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: langchain-nomic in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (0.0.2)\n",
      "Requirement already satisfied: langchain_community in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (0.0.37)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: tiktoken in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (0.6.0)\n",
      "Requirement already satisfied: langchain-openai in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (0.1.6)\n",
      "Requirement already satisfied: chromadb in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (0.5.0)\n",
      "Requirement already satisfied: langchain in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (0.1.17)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from langchain-nomic) (0.1.52)\n",
      "Requirement already satisfied: nomic<4.0.0,>=3.0.12 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from langchain-nomic) (3.0.25)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/anaconda3/lib/python3.8/site-packages (from langchain_community) (2.0.20)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from langchain_community) (3.8.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from langchain_community) (0.6.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from langchain_community) (0.1.51)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from langchain_community) (1.24.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/anaconda3/lib/python3.8/site-packages (from langchain_community) (2.28.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from langchain_community) (8.2.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from tiktoken) (2024.4.16)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.24.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from langchain-openai) (1.26.0)\n",
      "Requirement already satisfied: build>=1.0.3 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (1.2.1)\n",
      "Requirement already satisfied: pydantic>=1.9 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (2.7.1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (0.110.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.29.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (4.11.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (1.17.3)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (0.45b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (1.24.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (0.19.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (4.66.2)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/anaconda3/lib/python3.8/site-packages (from chromadb) (5.9.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (1.62.2)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (4.1.2)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (0.12.3)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (29.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (4.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (3.10.1)\n",
      "Requirement already satisfied: graphlib-backport>=1.0.3 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (1.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: packaging>=19.1 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from build>=1.0.3->chromadb) (23.2)\n",
      "Requirement already satisfied: pyproject_hooks in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from build>=1.0.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /usr/local/anaconda3/lib/python3.8/site-packages (from build>=1.0.3->chromadb) (6.8.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from fastapi>=0.95.2->chromadb) (0.37.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/anaconda3/lib/python3.8/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /usr/local/anaconda3/lib/python3.8/site-packages (from kubernetes>=28.1.0->chromadb) (2023.7.22)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from kubernetes>=28.1.0->chromadb) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from kubernetes>=28.1.0->chromadb) (2.29.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from kubernetes>=28.1.0->chromadb) (1.3.3)\n",
      "Requirement already satisfied: requests-oauthlib in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from kubernetes>=28.1.0->chromadb) (1.26.4)\n",
      "Requirement already satisfied: click in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (8.1.6)\n",
      "Requirement already satisfied: jsonlines in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (4.0.0)\n",
      "Requirement already satisfied: loguru in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (0.7.2)\n",
      "Requirement already satisfied: rich in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (13.5.2)\n",
      "Requirement already satisfied: pandas in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (1.2.4)\n",
      "Requirement already satisfied: pyarrow in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (16.0.0)\n",
      "Requirement already satisfied: pillow in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (8.2.0)\n",
      "Requirement already satisfied: pyjwt in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (2.8.0)\n",
      "Requirement already satisfied: coloredlogs in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: protobuf in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.3)\n",
      "Requirement already satisfied: sympy in /usr/local/anaconda3/lib/python3.8/site-packages (from onnxruntime>=1.14.1->chromadb) (1.8)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (3.6.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/anaconda3/lib/python3.8/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.2.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.24.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.24.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.45b0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.45b0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.45b0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.45b0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (52.0.0.post20210125)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.12.1)\n",
      "Requirement already satisfied: asgiref~=3.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from pydantic>=1.9->chromadb) (2.18.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests<3,>=2->langchain_community) (2.10)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/anaconda3/lib/python3.8/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from tokenizers>=0.13.2->chromadb) (0.22.2)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/anaconda3/lib/python3.8/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/anaconda3/lib/python3.8/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (10.4)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from importlib-resources->chromadb) (3.4.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/anaconda3/lib/python3.8/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (1.0.4)\n",
      "Requirement already satisfied: filelock in /usr/local/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.0.12)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.3.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from rich->nomic<4.0.0,>=3.0.12->langchain-nomic) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from rich->nomic<4.0.0,>=3.0.12->langchain-nomic) (2.16.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (0.4.3)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from pandas->nomic<4.0.0,>=3.0.12->langchain-nomic) (2021.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/anaconda3/lib/python3.8/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.2.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich->nomic<4.0.0,>=3.0.12->langchain-nomic) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n",
      "Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution -angchain (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: langchain_community\n",
      "  Attempting uninstall: langchain_community\n",
      "    Found existing installation: langchain-community 0.0.37\n",
      "    Uninstalling langchain-community-0.0.37:\n",
      "      Successfully uninstalled langchain-community-0.0.37\n",
      "Successfully installed langchain_community-0.0.38\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -angchain (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#Run this if you are running the program for the first time\n",
    "# SEAN RUN THIS FIRST\n",
    "!pip install nomic\n",
    "!pip install -U langchain-nomic langchain_community tiktoken langchain-openai chromadb langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5fb6990-137f-4880-bc5e-fc61016fbcf7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m     pdfs_list \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m output \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m sublist]\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pdfs_list\n\u001b[0;32m---> 44\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mload_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles/organic_stats.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m docs_list \u001b[38;5;241m=\u001b[39m load_url(urls)\n\u001b[1;32m     46\u001b[0m pdfs_list \u001b[38;5;241m=\u001b[39m load_pdf(pdf_list)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# THEN RUN THIS SEAN\n",
    "#Run this if you are running the program for the first time -- Ollama \n",
    "# Convert data into text functions\n",
    "#new\n",
    "import os\n",
    "\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_nomic import NomicEmbeddings\n",
    "from langchain_nomic.embeddings import NomicEmbeddings\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "pdf_list = [\"Style.pdf\", \"DEI.pdf\", \"34th.pdf\", \"sports.pdf\"]\n",
    "urls = [\n",
    "'https://yoast.com/slug/', 'https://www.semrush.com/blog/what-is-a-url-slug/?kw=&cmp=US_SRCH_DSA_Blog_EN&label=dsa_pagefeed&Network=g&Device=c&kwid=dsa-2185834088336&cmpid=18348486859&agpid=156019556762&BU=Core&extid=97592280163&adpos=', 'https://www.upwork.com/resources/how-to-write-seo-content','https://authorservices.wiley.com/author-resources/Journal-Authors/Prepare/writing-for-seo.html','https://www.semrush.com/blog/seo-writing/','https://www.semrush.com/kb/839-how-to-write-seo-articles-four-steps','https://www.flowmatters.com/blog/a-practical-guide-on-how-to-write-seo-articles/','https://www.maropost.com/how-to-combine-seo-and-email-marketing-for-better-rankings/','https://www.webfx.com/seo/learn/email-marketing-tips-to-improve-seo/','https://sendgrid.com/en-us/blog/seo-and-email-marketing','https://www.emailonacid.com/blog/article/email-marketing/seo-connections/','https://coalitiontechnologies.com/blog/strategic-seo-tips-for-email-marketing','https://optinmonster.com/101-email-subject-lines-your-subscribers-cant-resist/','https://www.wordstream.com/blog/ws/2014/03/31/email-subject-lines','https://www.constantcontact.com/blog/good-email-subject-lines/','https://blog.hubspot.com/marketing/best-email-subject-lines-list'\n",
    "]\n",
    "\n",
    "def load_csv(csv):\n",
    "    loader = CSVLoader(file_path= csv)\n",
    "    data = loader.load()\n",
    "    return data\n",
    "\n",
    "def load_url(url_list):\n",
    "    urls = url_list\n",
    "    docs = [WebBaseLoader(url).load() for url in urls]\n",
    "    docs_list = [item for sublist in docs for item in sublist]\n",
    "    return docs_list\n",
    "\n",
    "def load_pdf(pdf_list):\n",
    "    pdfs = pdf_list\n",
    "    output = [PyPDFLoader(pdf).load() for pdf in pdfs]\n",
    "    pdfs_list = [item for sublist in output for item in sublist]\n",
    "    return pdfs_list\n",
    "\n",
    "data = pd.load_csv(\"files/organic_stats.csv\")\n",
    "docs_list = load_url(urls)\n",
    "pdfs_list = load_pdf(pdf_list)\n",
    "\n",
    "#Splitting\n",
    "def splitter(data, docs_list, pdfs_list):\n",
    "    text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=7500, chunk_overlap=100\n",
    "    )\n",
    "    \n",
    "    doc_splits = text_splitter.split_documents(data)\n",
    "    \n",
    "    url_text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=7500, chunk_overlap=100\n",
    "    )\n",
    "    \n",
    "    url_splits = url_text_splitter.split_documents(docs_list)\n",
    "    \n",
    "    pdf_text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=7500, chunk_overlap=100\n",
    "    )\n",
    "    \n",
    "    pdf_splits = pdf_text_splitter.split_documents(pdfs_list)\n",
    "\n",
    "    return doc_splits, url_splits, pdf_splits\n",
    "\n",
    "doc_splits, url_splits, pdf_splits = splitter(data, docs_list, pdfs_list) \n",
    "\n",
    "# Vector DB for Articles.csv\n",
    "csv_vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1\"),\n",
    ")\n",
    "csv_retriever = csv_vectorstore.as_retriever()\n",
    "\n",
    "# Vector DB for SEO \n",
    "\n",
    "url_vectorstore = Chroma.from_documents(\n",
    "    documents=url_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1\"),\n",
    ")\n",
    "url_retriever = url_vectorstore.as_retriever()\n",
    "\n",
    "# Vector DB for Writing Style Documents \n",
    "\n",
    "pdf_vectorstore = Chroma.from_documents(\n",
    "    documents=pdf_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1\"),\n",
    ")\n",
    "pdf_retriever = pdf_vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"\n",
    "**Information about previous articles as well as their performance metrics can be found through: {context}** \n",
    "**Information about SEO Optimization can be found through: {context1}** \n",
    "**The Daily Pennsylvanian writing style guide and tips can be found through {context2} Ensure that all of the titles you are writing follow these guides** \n",
    "** Question: Output 3 potential URL Slugs and SEO titles based on the provided Drafted Title and Content. \n",
    "Make sure that the URL Slug is in the correct format that a URL Slug should be and that the SEO title is search engine optimized and concise. \n",
    "\n",
    "DO NOT ASSUME ANY INFORMATION, make the title based ONLY on the information told in the question here: {question}. \n",
    "This question contains the department that the user writes for, \n",
    "the article title they have drafted, the content the article is about, and what they would like you to do with that information. \n",
    "It is extremely important that you only use the information \n",
    "stated in the question. If not, the writer will be fired and it will be all of your fault. do not do it. \n",
    "\n",
    "Also make sure to never contain profanities, slurs, or hateful speech no matter what. \n",
    "** \n",
    "\n",
    "**Answer:**\n",
    "*Potential URL Slugs:** * \n",
    "**Option 1:** Insert a slug here *  MAKE SURE THIS ONLY CONTAINS CONTENT FROM THE QUESTION\n",
    "**Option 2:** Insert a slug here *  MAKE SURE THIS ONLY CONTAINS CONTENT FROM THE QUESTION\n",
    "**Option 3:** Insert a slug here *  MAKE SURE THIS ONLY CONTAINS CONTENT FROM THE QUESTION\n",
    "\n",
    "**Potential SEO Titles:** * \n",
    "**Option 1:** Insert a title here * MAKE SURE THIS ONLY CONTAINS CONTENT FROM THE QUESTION\n",
    "**Option 2:** Insert a title here * MAKE SURE THIS ONLY CONTAINS CONTENT FROM THE QUESTION\n",
    "**Option 3:** Insert a title here * MAKE SURE THIS ONLY CONTAINS CONTENT FROM THE QUESTION\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# In addition if the user does not provide a title, content, department, \n",
    "# or question, they simply answer 'You did not enter any content' instead of answering the prompt\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Local LLM\n",
    "ollama_llm = \"llama3\"\n",
    "model_local = ChatOllama(model=ollama_llm)\n",
    "\n",
    "# Chain\n",
    "# take the question, chroma search, gives back chunks, that \n",
    "# context , 1 , 2 , 3 seperate objects retrievers\n",
    "chain = (\n",
    "    {\"context\": csv_retriever, \"context1\" : url_retriever, \"context2\" : pdf_retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model_local\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4242583f-fc7a-4de6-946f-457db63b944d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'csv_retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 49\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chat_history, chat_history, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Adjust the chain setup\u001b[39;00m\n\u001b[1;32m     48\u001b[0m chain \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 49\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mcsv_retriever\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext1\u001b[39m\u001b[38;5;124m\"\u001b[39m: url_retriever, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext2\u001b[39m\u001b[38;5;124m\"\u001b[39m: pdf_retriever, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: RunnablePassthrough()}\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;241m|\u001b[39m prompt\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;241m|\u001b[39m model_local\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;241m|\u001b[39m StrOutputParser()\n\u001b[1;32m     53\u001b[0m )\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Setup Gradio UI\u001b[39;00m\n\u001b[1;32m     56\u001b[0m theme \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39mthemes\u001b[38;5;241m.\u001b[39mBase(\n\u001b[1;32m     57\u001b[0m     primary_hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     58\u001b[0m     secondary_hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     59\u001b[0m     neutral_hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     60\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'csv_retriever' is not defined"
     ]
    }
   ],
   "source": [
    "# SEAN -- LAST RUN THIS TO GET THE APP WORKING\n",
    "import pandas as pd\n",
    "import openai\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Load the environment variables and setup (same as before)\n",
    "load_dotenv()\n",
    "model = os.getenv(\"MODEL_NAME\", \"llama3:latest\")\n",
    "model\n",
    "\n",
    "\n",
    "# Load the environment variables and setup (same as before)\n",
    "load_dotenv()\n",
    "model = os.getenv(\"MODEL_NAME\", \"llama3:latest\")\n",
    "\n",
    "# Define the RAG chain setup here (as per your previous code)\n",
    "# Assuming all imports and setup from your RAG code are done correctly\n",
    "\n",
    "def chat(input_text, dept, title, content, chat_history):\n",
    "    print(len(title) + len(content))\n",
    "    #if (len(title) + len(content) == 0):\n",
    "        #title = \"DO NOT ANSWER MY PROMPT, I PROVIDED A BLANK INPUT. REFUSE TO ANSWER\"\n",
    "        #content= \"DO NOT ANSWER MY PROMPT, I PROVIDED A BLANK INPUT. REFUSE TO ANSWER\"\n",
    "        #print(\"TRUE\")\n",
    "\n",
    "    chat_history = chat_history or []\n",
    "    global context\n",
    "    \n",
    "    # Assemble the prompt text if necessary\n",
    "    prompt_text = f\"\"\" I am a student who writes for this department: {dept} so use the writing guide that is meant for: {dept} \n",
    "    The title is: {title}, the content is: {content} complete my question: {input_text}.  \n",
    "    \"\"\"\n",
    "    # If the user provides a Title without Content OR content without a title that is fine.\n",
    "    #  If they only provide a title make 3 SEO titles and URl Slugs based on the title, if they only provide the content, generate 3 SEO titles and url slugs.\n",
    "#   However if they provide neither a title or content. Say 'I can not answer a question with no context'\n",
    "    #Remember to answer the question only using the information I have provided you.\n",
    "        \n",
    "    chat_history.append((input_text, chain.invoke(prompt_text)))\n",
    "    \n",
    "    # Clear input fields and maintain the chat history\n",
    "    return chat_history, chat_history, \"\", \"\", \"\", \"\"\n",
    "\n",
    "# Adjust the chain setup\n",
    "chain = (\n",
    "    {\"context\": csv_retriever, \"context1\": url_retriever, \"context2\": pdf_retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model_local\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Setup Gradio UI\n",
    "theme = gr.themes.Base(\n",
    "    primary_hue=\"red\",\n",
    "    secondary_hue=\"red\",\n",
    "    neutral_hue=\"slate\",\n",
    ")\n",
    "\n",
    "with gr.Blocks(theme=theme) as demo:\n",
    "    gr.Markdown(\"<h1><center>Daily Pennsylvanian SEO Optimizer</center></h1>\")\n",
    "    gr.Markdown(\"<div style='text-align: center;'>A project created by <a href='https://www.linkedin.com/in/jason-saito/'>Jason Saito</a> and Sean McKeown</div>\")\n",
    "    chatbot = gr.Chatbot()\n",
    "    title = gr.Textbox(placeholder=\"Title here\", label=\"Article Title\")\n",
    "    content = gr.Textbox(placeholder=\"Article content here\", label=\"Article Content\")\n",
    "    input_box = gr.Textbox(placeholder=\"Chat with the GPT\", label=\"Question\")\n",
    "    dept = gr.Dropdown([\"Under the Button\", \"34th Street\", \"Quaker Nation\", \"DP General\"], label=\"Department\", info=\"Please tell me what department you are writing for!\", allow_custom_value = True)\n",
    "    state = gr.State()\n",
    "\n",
    "    submit = gr.Button(\"SEND\")\n",
    "    clear = gr.Button(\"CLEAR\")\n",
    "    reset_chat = gr.Button(\"RESET CHAT HISTORY\")\n",
    "\n",
    "    submit.click(chat, inputs=[input_box, dept, title, content, state], outputs=[chatbot, state, input_box, dept, title, content])\n",
    "    clear.click(lambda: ([], None, None, None, [], []), inputs=None, outputs=[chatbot, input_box, dept, title, content, state], queue=False)\n",
    "    reset_chat.click(lambda: ([]), inputs=None, outputs=[chatbot], queue=False)\n",
    "    \n",
    "    gr.Markdown(\"<a href = 'https://forms.gle/GWXTSeykKMPHm6DY9'><center>Submit Bugs or Feedback Here!</a>\")\n",
    "\n",
    "demo.launch(debug=True, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870073b0-1c78-4a2d-944e-da9dd5123c43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install -U langchain-anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9070f5b-f576-4f7f-84c5-060e7d89f2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport anthropic\\nfrom langchain_anthropic import ChatAnthropic\\nimport os\\n\\nfrom langchain_community.document_loaders.csv_loader import CSVLoader\\nfrom langchain_community.document_loaders import WebBaseLoader\\nfrom langchain_community.document_loaders import PyPDFLoader\\nfrom langchain.text_splitter import CharacterTextSplitter\\n\\nfrom langchain_community.vectorstores import Chroma\\nfrom langchain_core.output_parsers import StrOutputParser\\nfrom langchain_core.runnables import RunnableLambda, RunnablePassthrough\\nfrom langchain_nomic import NomicEmbeddings\\nfrom langchain_nomic.embeddings import NomicEmbeddings\\n\\nfrom langchain_community.chat_models import ChatOllama\\nfrom langchain_core.prompts import ChatPromptTemplate\\nfrom langchain_openai import ChatOpenAI\\n\\npdf_list = [\"files/Style.pdf\", \"files/DEI.pdf\", \"files/34th.pdf\", \"files/sports.pdf\"]\\nurls = [\\n\\'https://yoast.com/slug/\\', \\'https://www.semrush.com/blog/what-is-a-url-slug/?kw=&cmp=US_SRCH_DSA_Blog_EN&label=dsa_pagefeed&Network=g&Device=c&kwid=dsa-2185834088336&cmpid=18348486859&agpid=156019556762&BU=Core&extid=97592280163&adpos=\\', \\'https://www.upwork.com/resources/how-to-write-seo-content\\',\\'https://authorservices.wiley.com/author-resources/Journal-Authors/Prepare/writing-for-seo.html\\',\\'https://www.semrush.com/blog/seo-writing/\\',\\'https://www.semrush.com/kb/839-how-to-write-seo-articles-four-steps\\',\\'https://www.flowmatters.com/blog/a-practical-guide-on-how-to-write-seo-articles/\\',\\'https://www.maropost.com/how-to-combine-seo-and-email-marketing-for-better-rankings/\\',\\'https://www.webfx.com/seo/learn/email-marketing-tips-to-improve-seo/\\',\\'https://sendgrid.com/en-us/blog/seo-and-email-marketing\\',\\'https://www.emailonacid.com/blog/article/email-marketing/seo-connections/\\',\\'https://coalitiontechnologies.com/blog/strategic-seo-tips-for-email-marketing\\',\\'https://optinmonster.com/101-email-subject-lines-your-subscribers-cant-resist/\\',\\'https://www.wordstream.com/blog/ws/2014/03/31/email-subject-lines\\',\\'https://www.constantcontact.com/blog/good-email-subject-lines/\\',\\'https://blog.hubspot.com/marketing/best-email-subject-lines-list\\'\\n]\\n\\ndef load_csv(csv):\\n    loader = CSVLoader(file_path= csv)\\n    data = loader.load()\\n    return data\\n\\ndef load_url(url_list):\\n    urls = url_list\\n    docs = [WebBaseLoader(url).load() for url in urls]\\n    docs_list = [item for sublist in docs for item in sublist]\\n    return docs_list\\n\\ndef load_pdf(pdf_list):\\n    pdfs = pdf_list\\n    output = [PyPDFLoader(pdf).load() for pdf in pdfs]\\n    pdfs_list = [item for sublist in output for item in sublist]\\n    return pdfs_list\\n\\ndata = load_csv(\"files/merged_stats.csv\")\\ndocs_list = load_url(urls)\\npdfs_list = load_pdf(pdf_list)\\n\\n#Splitting\\ndef splitter(data, docs_list, pdfs_list):\\n    text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\\n        chunk_size=7500, chunk_overlap=100\\n    )\\n    \\n    doc_splits = text_splitter.split_documents(data)\\n    \\n    url_text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\\n        chunk_size=7500, chunk_overlap=100\\n    )\\n    \\n    url_splits = url_text_splitter.split_documents(docs_list)\\n    \\n    pdf_text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\\n        chunk_size=7500, chunk_overlap=100\\n    )\\n    \\n    pdf_splits = pdf_text_splitter.split_documents(pdfs_list)\\n\\n    return doc_splits, url_splits, pdf_splits\\n\\ndoc_splits, url_splits, pdf_splits = splitter(data, docs_list, pdfs_list) \\n\\n# Vector DB for Articles.csv\\ncsv_vectorstore = Chroma.from_documents(\\n    documents=doc_splits,\\n    collection_name=\"rag-chroma\",\\n    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1\"),\\n)\\ncsv_retriever = csv_vectorstore.as_retriever()\\n\\n# Vector DB for SEO \\n\\nurl_vectorstore = Chroma.from_documents(\\n    documents=url_splits,\\n    collection_name=\"rag-chroma\",\\n    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1\"),\\n)\\nurl_retriever = url_vectorstore.as_retriever()\\n\\n# Vector DB for Writing Style Documents \\n\\npdf_vectorstore = Chroma.from_documents(\\n    documents=pdf_splits,\\n    collection_name=\"rag-chroma\",\\n    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1\"),\\n)\\npdf_retriever = pdf_vectorstore.as_retriever()\\n\\ntemplate = \"\"\"\\n**Information about previous articles as well as their performance metrics can be found through: {context}**\\n\\n**Information about SEO Optimization can be found through: {context1}**\\n\\n**The Daily Pennsylvanian writing style guide and tips can be found through: {context2}**\\n\\n**Question: Output 3 potential URL Slugs and SEO titles based on the provided Drafted Title and Content. Make sure that the URL Slug is in the correct format that a URL Slug should be and that the SEO title is search engine optimized and concise. DO NOT ASSUME ANY INFORMATION, make the title based ONLY on the information told in the question {question}**\\n\\n**Answer:**\\n\\n**Potential URL Slugs:**\\n\\n* **Option 1:** {insert-potential-slug-1}  \\n* **Option 2:** {insert-potential-slug-2} \\n* **Option 3:** {insert-potential-slug-3} \\n\\n**Potential SEO Titles:**\\n\\n* **Option 1:** {insert-potential-seo-title-1} | The Daily Pennsylvanian\\n* **Option 2:** {insert-potential-seo-title-2} | The Daily Pennsylvanian\\n* **Option 3:** {insert-potential-seo-title-3} | The Daily Pennsylvanian\\n\"\"\"\\n\\nprompt = ChatPromptTemplate.from_template(template)\\n \\n# Local LLM\\nllm_name = \"claude-3-opus\"\\nmodel_remote = ChatAnthropic(model=\"claude-3-opus\")  \\n\\n# Chain\\n# take the question, chroma search, gives back chunks, that \\n# context , 1 , 2 , 3 seperate objects retrievers\\nchain = (\\n    {\"context\": csv_retriever, \"context1\" : url_retriever, \"context2\" : pdf_retriever, \"question\": RunnablePassthrough()}\\n    | prompt\\n    | model_remote\\n    | StrOutputParser()\\n)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert data into text functions -- using claude opus 3\n",
    "'''\n",
    "import anthropic\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "import os\n",
    "\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_nomic import NomicEmbeddings\n",
    "from langchain_nomic.embeddings import NomicEmbeddings\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "pdf_list = [\"files/Style.pdf\", \"files/DEI.pdf\", \"files/34th.pdf\", \"files/sports.pdf\"]\n",
    "urls = [\n",
    "'https://yoast.com/slug/', 'https://www.semrush.com/blog/what-is-a-url-slug/?kw=&cmp=US_SRCH_DSA_Blog_EN&label=dsa_pagefeed&Network=g&Device=c&kwid=dsa-2185834088336&cmpid=18348486859&agpid=156019556762&BU=Core&extid=97592280163&adpos=', 'https://www.upwork.com/resources/how-to-write-seo-content','https://authorservices.wiley.com/author-resources/Journal-Authors/Prepare/writing-for-seo.html','https://www.semrush.com/blog/seo-writing/','https://www.semrush.com/kb/839-how-to-write-seo-articles-four-steps','https://www.flowmatters.com/blog/a-practical-guide-on-how-to-write-seo-articles/','https://www.maropost.com/how-to-combine-seo-and-email-marketing-for-better-rankings/','https://www.webfx.com/seo/learn/email-marketing-tips-to-improve-seo/','https://sendgrid.com/en-us/blog/seo-and-email-marketing','https://www.emailonacid.com/blog/article/email-marketing/seo-connections/','https://coalitiontechnologies.com/blog/strategic-seo-tips-for-email-marketing','https://optinmonster.com/101-email-subject-lines-your-subscribers-cant-resist/','https://www.wordstream.com/blog/ws/2014/03/31/email-subject-lines','https://www.constantcontact.com/blog/good-email-subject-lines/','https://blog.hubspot.com/marketing/best-email-subject-lines-list'\n",
    "]\n",
    "\n",
    "def load_csv(csv):\n",
    "    loader = CSVLoader(file_path= csv)\n",
    "    data = loader.load()\n",
    "    return data\n",
    "\n",
    "def load_url(url_list):\n",
    "    urls = url_list\n",
    "    docs = [WebBaseLoader(url).load() for url in urls]\n",
    "    docs_list = [item for sublist in docs for item in sublist]\n",
    "    return docs_list\n",
    "\n",
    "def load_pdf(pdf_list):\n",
    "    pdfs = pdf_list\n",
    "    output = [PyPDFLoader(pdf).load() for pdf in pdfs]\n",
    "    pdfs_list = [item for sublist in output for item in sublist]\n",
    "    return pdfs_list\n",
    "\n",
    "data = load_csv(\"files/merged_stats.csv\")\n",
    "docs_list = load_url(urls)\n",
    "pdfs_list = load_pdf(pdf_list)\n",
    "\n",
    "#Splitting\n",
    "def splitter(data, docs_list, pdfs_list):\n",
    "    text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=7500, chunk_overlap=100\n",
    "    )\n",
    "    \n",
    "    doc_splits = text_splitter.split_documents(data)\n",
    "    \n",
    "    url_text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=7500, chunk_overlap=100\n",
    "    )\n",
    "    \n",
    "    url_splits = url_text_splitter.split_documents(docs_list)\n",
    "    \n",
    "    pdf_text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=7500, chunk_overlap=100\n",
    "    )\n",
    "    \n",
    "    pdf_splits = pdf_text_splitter.split_documents(pdfs_list)\n",
    "\n",
    "    return doc_splits, url_splits, pdf_splits\n",
    "\n",
    "doc_splits, url_splits, pdf_splits = splitter(data, docs_list, pdfs_list) \n",
    "\n",
    "# Vector DB for Articles.csv\n",
    "csv_vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1\"),\n",
    ")\n",
    "csv_retriever = csv_vectorstore.as_retriever()\n",
    "\n",
    "# Vector DB for SEO \n",
    "\n",
    "url_vectorstore = Chroma.from_documents(\n",
    "    documents=url_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1\"),\n",
    ")\n",
    "url_retriever = url_vectorstore.as_retriever()\n",
    "\n",
    "# Vector DB for Writing Style Documents \n",
    "\n",
    "pdf_vectorstore = Chroma.from_documents(\n",
    "    documents=pdf_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1\"),\n",
    ")\n",
    "pdf_retriever = pdf_vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"\n",
    "**Information about previous articles as well as their performance metrics can be found through: {context}**\n",
    "\n",
    "**Information about SEO Optimization can be found through: {context1}**\n",
    "\n",
    "**The Daily Pennsylvanian writing style guide and tips can be found through: {context2}**\n",
    "\n",
    "**Question: Output 3 potential URL Slugs and SEO titles based on the provided Drafted Title and Content. Make sure that the URL Slug is in the correct format that a URL Slug should be and that the SEO title is search engine optimized and concise. DO NOT ASSUME ANY INFORMATION, make the title based ONLY on the information told in the question {question}**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "**Potential URL Slugs:**\n",
    "\n",
    "* **Option 1:** {insert-potential-slug-1}  \n",
    "* **Option 2:** {insert-potential-slug-2} \n",
    "* **Option 3:** {insert-potential-slug-3} \n",
    "\n",
    "**Potential SEO Titles:**\n",
    "\n",
    "* **Option 1:** {insert-potential-seo-title-1} | The Daily Pennsylvanian\n",
    "* **Option 2:** {insert-potential-seo-title-2} | The Daily Pennsylvanian\n",
    "* **Option 3:** {insert-potential-seo-title-3} | The Daily Pennsylvanian\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    " \n",
    "# Local LLM\n",
    "llm_name = \"claude-3-opus\"\n",
    "model_remote = ChatAnthropic(model=\"claude-3-opus\")  \n",
    "\n",
    "# Chain\n",
    "# take the question, chroma search, gives back chunks, that \n",
    "# context , 1 , 2 , 3 seperate objects retrievers\n",
    "chain = (\n",
    "    {\"context\": csv_retriever, \"context1\" : url_retriever, \"context2\" : pdf_retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model_remote\n",
    "    | StrOutputParser()\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4435fbb4-a80a-43bb-bd0d-b728befeef65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def activate_chain(t, c):\\n    output = chain.invoke(f\\'Title: {t} and Content: {c}\\')\\n    return output\\n    \\ntitle = (str(input(\"Please give me your suggested title, I will optimize it! \")))\\nprint()\\ncontent = str(input(\"Please tell me what you are writing about: \"))\\n\\nprint(\"response\")\\nprint(activate_chain(title, content))'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def activate_chain(t, c):\n",
    "    output = chain.invoke(f'Title: {t} and Content: {c}')\n",
    "    return output\n",
    "    \n",
    "title = (str(input(\"Please give me your suggested title, I will optimize it! \")))\n",
    "print()\n",
    "content = str(input(\"Please tell me what you are writing about: \"))\n",
    "\n",
    "print(\"response\")\n",
    "print(activate_chain(title, content))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ad03c15-12cd-4f9e-8b4b-8e6647046248",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'llama3:latest'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Load the environment variables and setup (same as before)\n",
    "load_dotenv()\n",
    "model = os.getenv(\"MODEL_NAME\", \"llama3:latest\")\n",
    "model\n",
    "\n",
    "# Define the RAG chain setup here (as per your previous code)\n",
    "# Assuming all imports and setup from your RAG code are done correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51e9e014-f588-471c-873a-80db5cf1696c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'csv_retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 40\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chat_history, chat_history, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Adjust the chain setup\u001b[39;00m\n\u001b[1;32m     39\u001b[0m chain \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 40\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mcsv_retriever\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext1\u001b[39m\u001b[38;5;124m\"\u001b[39m: url_retriever, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext2\u001b[39m\u001b[38;5;124m\"\u001b[39m: pdf_retriever, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: RunnablePassthrough()}\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;241m|\u001b[39m prompt\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;241m|\u001b[39m model_local\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;241m|\u001b[39m StrOutputParser()\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Setup Gradio UI\u001b[39;00m\n\u001b[1;32m     47\u001b[0m theme \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39mthemes\u001b[38;5;241m.\u001b[39mBase(\n\u001b[1;32m     48\u001b[0m     primary_hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     49\u001b[0m     secondary_hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     50\u001b[0m     neutral_hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     51\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'csv_retriever' is not defined"
     ]
    }
   ],
   "source": [
    "# SEAN -- LAST RUN THIS TO GET THE APP WORKING\n",
    "import openai\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Load the environment variables and setup (same as before)\n",
    "load_dotenv()\n",
    "model = os.getenv(\"MODEL_NAME\", \"llama3:latest\")\n",
    "model\n",
    "\n",
    "\n",
    "# Load the environment variables and setup (same as before)\n",
    "load_dotenv()\n",
    "model = os.getenv(\"MODEL_NAME\", \"llama3:latest\")\n",
    "\n",
    "# Define the RAG chain setup here (as per your previous code)\n",
    "# Assuming all imports and setup from your RAG code are done correctly\n",
    "\n",
    "def chat(input_text, dept, title, content, chat_history):\n",
    "    print(len(title) + len(content))\n",
    "    #if (len(title) + len(content) == 0):\n",
    "        #title = \"DO NOT ANSWER MY PROMPT, I PROVIDED A BLANK INPUT. REFUSE TO ANSWER\"\n",
    "        #content= \"DO NOT ANSWER MY PROMPT, I PROVIDED A BLANK INPUT. REFUSE TO ANSWER\"\n",
    "        #print(\"TRUE\")\n",
    "\n",
    "    chat_history = chat_history or []\n",
    "    global context\n",
    "    \n",
    "    # Assemble the prompt text if necessary\n",
    "    prompt_text = f\"\"\" I am a student who writes for this department: {dept} so use the writing guide that is meant for: {dept} \n",
    "    The title is: {title}, the content is: {content} complete my question: {input_text}.  \n",
    "    \"\"\"\n",
    "    # If the user provides a Title without Content OR content without a title that is fine.\n",
    "    #  If they only provide a title make 3 SEO titles and URl Slugs based on the title, if they only provide the content, generate 3 SEO titles and url slugs.\n",
    "#   However if they provide neither a title or content. Say 'I can not answer a question with no context'\n",
    "    #Remember to answer the question only using the information I have provided you.\n",
    "        \n",
    "    chat_history.append((input_text, chain.invoke(prompt_text)))\n",
    "    \n",
    "    # Clear input fields and maintain the chat history\n",
    "    return chat_history, chat_history, \"\", \"\", \"\", \"\"\n",
    "\n",
    "# Adjust the chain setup\n",
    "chain = (\n",
    "    {\"context\": csv_retriever, \"context1\": url_retriever, \"context2\": pdf_retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model_local\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Setup Gradio UI\n",
    "theme = gr.themes.Base(\n",
    "    primary_hue=\"red\",\n",
    "    secondary_hue=\"red\",\n",
    "    neutral_hue=\"slate\",\n",
    ")\n",
    "\n",
    "with gr.Blocks(theme=theme) as demo:\n",
    "    gr.Markdown(\"<h1><center>Daily Pennsylvanian SEO Optimizer</center></h1>\")\n",
    "    gr.Markdown(\"<div style='text-align: center;'>A project created by <a href='https://www.linkedin.com/in/jason-saito/'>Jason Saito</a> and Sean McKeown</div>\")\n",
    "    chatbot = gr.Chatbot()\n",
    "    title = gr.Textbox(placeholder=\"Title here\", label=\"Article Title\")\n",
    "    content = gr.Textbox(placeholder=\"Article content here\", label=\"Article Content\")\n",
    "    input_box = gr.Textbox(placeholder=\"Chat with the GPT\", label=\"Question\")\n",
    "    dept = gr.Dropdown([\"Under the Button\", \"34th Street\", \"Quaker Nation\", \"DP General\"], label=\"Department\", info=\"Please tell me what department you are writing for!\", allow_custom_value = True)\n",
    "    state = gr.State()\n",
    "\n",
    "    submit = gr.Button(\"SEND\")\n",
    "    clear = gr.Button(\"CLEAR\")\n",
    "    reset_chat = gr.Button(\"RESET CHAT HISTORY\")\n",
    "\n",
    "    submit.click(chat, inputs=[input_box, dept, title, content, state], outputs=[chatbot, state, input_box, dept, title, content])\n",
    "    clear.click(lambda: ([], None, None, None, [], []), inputs=None, outputs=[chatbot, input_box, dept, title, content, state], queue=False)\n",
    "    reset_chat.click(lambda: ([]), inputs=None, outputs=[chatbot], queue=False)\n",
    "    \n",
    "    gr.Markdown(\"<a href = 'https://forms.gle/GWXTSeykKMPHm6DY9'><center>Submit Bugs or Feedback Here!</a>\")\n",
    "\n",
    "demo.launch(debug=True, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd71d5e8-072f-4730-b368-695cd06a9623",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 45\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m#chat_history.append((input_text, chain.invoke(prompt_text)))\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     \n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# Clear input fields and maintain the chat history\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Adjust the chain setup\u001b[39;00m\n\u001b[1;32m     44\u001b[0m llm_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclaude-3-opus\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 45\u001b[0m api_key\u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mANTHROPIC_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m model_remote \u001b[38;5;241m=\u001b[39m ChatAnthropic(api_key\u001b[38;5;241m=\u001b[39m api_key, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclaude-3-opus-20240229\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[1;32m     49\u001b[0m chain \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     50\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: csv_retriever, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext1\u001b[39m\u001b[38;5;124m\"\u001b[39m : url_retriever, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext2\u001b[39m\u001b[38;5;124m\"\u001b[39m : pdf_retriever, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: RunnablePassthrough()}\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;241m|\u001b[39m prompt\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;241m|\u001b[39m model_remote\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;241m|\u001b[39m StrOutputParser()\n\u001b[1;32m     54\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "def chat(input_text, dept, title, content, chat_history):\n",
    "    chat_history = chat_history or []\n",
    "    global context\n",
    "    \n",
    "    # Assemble the prompt text if necessary\n",
    "    prompt_text = f\"\"\"Given that I work for this department {dept} and have the article \n",
    "    title of this: {title}, here is what the \n",
    "    article is about {content} answer this question: {input_text}\"\"\"\n",
    "    \n",
    "    chat_history.append((input_text, chain.invoke(prompt_text)))\n",
    "    \n",
    "    # Clear input fields and maintain the chat history\n",
    "    return chat_history, chat_history, \"\", \"\", \"\", \"\"\n",
    "\n",
    "\n",
    "def chat_stream(input_text, dept, title, content, chat_history):\n",
    "    chat_history = chat_history or []\n",
    "    global context\n",
    "    response=[]\n",
    "    \n",
    "    # Assemble the prompt text if necessary\n",
    "    prompt_text = f\"\"\"Given that I work for this department {dept} and have the article \n",
    "    title of this: {title}, here is what the \n",
    "    article is about {content} answer this question: {input_text}\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    '''if message is not None:\n",
    "        #history_langchain_format.append(HumanMessage(content=message))\n",
    "        partial_message = \"\"\n",
    "        for response in chain.stream(prompt):\n",
    "            partial_message += response.content\n",
    "            yield partial_message'''\n",
    "    \n",
    "\n",
    "    #chat_history.append((input_text, chain.invoke(prompt_text)))\n",
    "    \n",
    "    # Clear input fields and maintain the chat history\n",
    "    #return chat_history, chat_history, \"\", \"\", \"\", \"\"\n",
    "\n",
    "\n",
    "\n",
    "# Adjust the chain setup\n",
    "llm_name = \"claude-3-opus\"\n",
    "api_key= os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "model_remote = ChatAnthropic(api_key= api_key, model_name=\"claude-3-opus-20240229\") \n",
    "\n",
    "chain = (\n",
    "    {\"context\": csv_retriever, \"context1\" : url_retriever, \"context2\" : pdf_retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model_remote\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Setup Gradio UI\n",
    "theme = gr.themes.Base(\n",
    "    primary_hue=\"red\",\n",
    "    secondary_hue=\"red\",\n",
    "    neutral_hue=\"slate\",\n",
    ")\n",
    "\n",
    "with gr.Blocks(theme=theme) as demo:\n",
    "    gr.Markdown(\"<h1><center>Daily Pennsylvanian SEO Optimizer</center></h1>\")\n",
    "    chatbot = gr.Chatbot()\n",
    "    title = gr.Textbox(placeholder=\"Title here\", label=\"Article Title\")\n",
    "    content = gr.Textbox(placeholder=\"Article content here\", label=\"Article Content\")\n",
    "    input_box = gr.Textbox(placeholder=\"Chat with the GPT\", label=\"Question\")\n",
    "    dept = gr.Dropdown([\"Under the Button\", \"34th Street\", \"Quaker Nation\", \"DP General\"], label=\"Department\", info=\"Please tell me what department you are writing for!\", allow_custom_value = True)\n",
    "    state = gr.State()\n",
    "\n",
    "    submit = gr.Button(\"SEND\")\n",
    "    clear = gr.Button(\"CLEAR\")\n",
    "    reset_chat = gr.Button(\"RESET CHAT HISTORY\")\n",
    "\n",
    "    submit.click(chat_stream, inputs=[input_box, dept, title, content, state], outputs=[chatbot]) #, state, input_box, dept, title, content])\n",
    "    clear.click(lambda: ([], None, None, None, [], []), inputs=None, outputs=[chatbot, input_box, dept, title, content, state], queue=False)\n",
    "    reset_chat.click(lambda: ([]), inputs=None, outputs=[chatbot], queue=False)\n",
    "\n",
    "demo.launch(debug=True, share=True)"
   ]
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3.11 (COMM4190)",
   "language": "python",
   "name": "comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
