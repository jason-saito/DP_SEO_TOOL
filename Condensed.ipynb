{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51c98305",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<<<<<<< local\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting nomic\n",
      "  Downloading nomic-3.0.27.tar.gz (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m164.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: click in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic) (8.1.6)\n",
      "Collecting jsonlines (from nomic)\n",
      "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting loguru (from nomic)\n",
      "  Downloading loguru-0.7.2-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: rich in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic) (13.5.2)\n",
      "Requirement already satisfied: requests in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic) (2.28.1)\n",
      "Requirement already satisfied: numpy in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic) (1.20.1)\n",
      "Requirement already satisfied: pandas in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic) (1.2.4)\n",
      "Collecting pydantic (from nomic)\n",
      "  Downloading pydantic-2.7.1-py3-none-any.whl.metadata (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m373.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic) (4.59.0)\n",
      "Collecting pyarrow (from nomic)\n",
      "  Downloading pyarrow-16.0.0-cp38-cp38-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: pillow in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic) (8.2.0)\n",
      "Collecting pyjwt (from nomic)\n",
      "  Downloading PyJWT-2.8.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from jsonlines->nomic) (23.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from pandas->nomic) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from pandas->nomic) (2021.1)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic->nomic)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.18.2 (from pydantic->nomic)\n",
      "  Downloading pydantic_core-2.18.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from pydantic->nomic) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests->nomic) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests->nomic) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests->nomic) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests->nomic) (2023.7.22)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from rich->nomic) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from rich->nomic) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich->nomic) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->nomic) (1.15.0)\n",
      "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
      "Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m255.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-16.0.0-cp38-cp38-manylinux_2_28_x86_64.whl (40.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.7.1-py3-none-any.whl (409 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.3/409.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.18.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
      "Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: nomic\n",
      "  Building wheel for nomic (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nomic: filename=nomic-3.0.27-py3-none-any.whl size=44143 sha256=e849ecd168dbc424a493d289d5b2bac7e3ce93d06a6633f9124d7875a4370885\n",
      "  Stored in directory: /Commjhub/jupyterhub/home/seanmckeown1/.cache/pip/wheels/04/f9/cb/a1f3f37d0f48a0eed581950482bf3ec2be7707725fdb7d82bf\n",
      "Successfully built nomic\n",
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: pyjwt, pydantic-core, pyarrow, loguru, jsonlines, annotated-types, pydantic, nomic\n",
      "\u001b[33m  WARNING: The script nomic is installed in '/Commjhub/jupyterhub/home/seanmckeown1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed annotated-types-0.6.0 jsonlines-4.0.0 loguru-0.7.2 nomic-3.0.27 pyarrow-16.0.0 pydantic-2.7.1 pydantic-core-2.18.2 pyjwt-2.8.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting langchain-nomic\n",
      "  Downloading langchain_nomic-0.0.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.6.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.1.6-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-0.5.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.1.19-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langchain-core<0.2,>=0.1 (from langchain-nomic)\n",
      "  Downloading langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: nomic<4.0.0,>=3.0.12 in /Commjhub/jupyterhub/home/seanmckeown1/.local/lib/python3.8/site-packages (from langchain-nomic) (3.0.27)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/anaconda3/lib/python3.8/site-packages (from langchain_community) (2.0.20)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from langchain_community) (3.8.3)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.5-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.0 (from langchain_community)\n",
      "  Downloading langsmith-0.1.56-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/anaconda3/lib/python3.8/site-packages (from langchain_community) (1.20.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/anaconda3/lib/python3.8/site-packages (from langchain_community) (2.28.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from langchain_community) (8.2.3)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2024.4.28-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m146.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting openai<2.0.0,>=1.24.0 (from langchain-openai)\n",
      "  Downloading openai-1.27.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.2.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in /Commjhub/jupyterhub/home/seanmckeown1/.local/lib/python3.8/site-packages (from chromadb) (2.7.1)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
      "  Downloading chroma_hnswlib-0.7.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
      "Collecting fastapi>=0.95.2 (from chromadb)\n",
      "  Downloading fastapi-0.111.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvicorn-0.29.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting numpy<2,>=1 (from langchain_community)\n",
      "  Downloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from chromadb) (4.7.1)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.17.3-cp38-cp38-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.24.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.24.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb)\n",
      "  Downloading tokenizers-0.19.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m480.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tqdm>=4.65.0 (from chromadb)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m257.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: overrides>=7.3.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/anaconda3/lib/python3.8/site-packages (from chromadb) (5.9.0)\n",
      "Collecting grpcio>=1.58.0 (from chromadb)\n",
      "  Downloading grpcio-1.63.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.1.3-cp37-abi3-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-4.1.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb)\n",
      "  Downloading orjson-3.10.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m269.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting graphlib-backport>=1.0.3 (from chromadb)\n",
      "  Downloading graphlib_backport-1.1.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from langchain) (4.0.2)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: packaging>=19.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from build>=1.0.3->chromadb) (23.1)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.1.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /usr/local/anaconda3/lib/python3.8/site-packages (from build>=1.0.3->chromadb) (6.8.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.21.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi>=0.95.2->chromadb)\n",
      "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting typing-extensions>=4.5.0 (from chromadb)\n",
      "  Downloading typing_extensions-4.11.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting fastapi-cli>=0.0.2 (from fastapi>=0.95.2->chromadb)\n",
      "  Downloading fastapi_cli-0.0.3-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from fastapi>=0.95.2->chromadb) (0.27.0)\n",
      "Requirement already satisfied: jinja2>=2.11.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from fastapi>=0.95.2->chromadb) (3.1.2)\n",
      "Collecting python-multipart>=0.0.7 (from fastapi>=0.95.2->chromadb)\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi>=0.95.2->chromadb)\n",
      "  Downloading ujson-5.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
      "Collecting email_validator>=2.0.0 (from fastapi>=0.95.2->chromadb)\n",
      "  Downloading email_validator-2.1.1-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /usr/local/anaconda3/lib/python3.8/site-packages (from kubernetes>=28.1.0->chromadb) (2023.7.22)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from kubernetes>=28.1.0->chromadb) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading google_auth-2.29.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from kubernetes>=28.1.0->chromadb) (1.3.3)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from kubernetes>=28.1.0->chromadb) (1.26.4)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2,>=0.1->langchain-nomic)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging>=19.1 (from build>=1.0.3->chromadb)\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: click in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (8.1.6)\n",
      "Requirement already satisfied: jsonlines in /Commjhub/jupyterhub/home/seanmckeown1/.local/lib/python3.8/site-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (4.0.0)\n",
      "Requirement already satisfied: loguru in /Commjhub/jupyterhub/home/seanmckeown1/.local/lib/python3.8/site-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (0.7.2)\n",
      "Requirement already satisfied: rich in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (13.5.2)\n",
      "Requirement already satisfied: pandas in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (1.2.4)\n",
      "Requirement already satisfied: pyarrow in /Commjhub/jupyterhub/home/seanmckeown1/.local/lib/python3.8/site-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (16.0.0)\n",
      "Requirement already satisfied: pillow in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (8.2.0)\n",
      "Requirement already satisfied: pyjwt in /Commjhub/jupyterhub/home/seanmckeown1/.local/lib/python3.8/site-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (2.8.0)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: sympy in /usr/local/anaconda3/lib/python3.8/site-packages (from onnxruntime>=1.14.1->chromadb) (1.8)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (3.6.1)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.24.0->langchain-openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: sniffio in /usr/local/anaconda3/lib/python3.8/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.2.0)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting opentelemetry-proto==1.24.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-instrumentation==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation-0.45b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-util-http==0.45b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_util_http-0.45b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (52.0.0.post20210125)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.12.1)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Commjhub/jupyterhub/home/seanmckeown1/.local/lib/python3.8/site-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Commjhub/jupyterhub/home/seanmckeown1/.local/lib/python3.8/site-packages (from pydantic>=1.9->chromadb) (2.18.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests<3,>=2->langchain_community) (2.10)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/anaconda3/lib/python3.8/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.0)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers>=0.13.2->chromadb)\n",
      "  Downloading huggingface_hub-0.23.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/anaconda3/lib/python3.8/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvloop-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-0.21.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/anaconda3/lib/python3.8/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (10.4)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from importlib-resources->chromadb) (3.4.1)\n",
      "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb)\n",
      "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/anaconda3/lib/python3.8/site-packages (from httpx>=0.23.0->fastapi>=0.95.2->chromadb) (1.0.4)\n",
      "Requirement already satisfied: filelock in /usr/local/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.0.12)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb)\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from jinja2>=2.11.2->fastapi>=0.95.2->chromadb) (2.1.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/anaconda3/lib/python3.8/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1->langchain-nomic) (2.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from rich->nomic<4.0.0,>=3.0.12->langchain-nomic) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from rich->nomic<4.0.0,>=3.0.12->langchain-nomic) (2.16.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (0.4.3)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from pandas->nomic<4.0.0,>=3.0.12->langchain-nomic) (2021.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/anaconda3/lib/python3.8/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.2.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich->nomic<4.0.0,>=3.0.12->langchain-nomic) (0.1.2)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Downloading langchain_nomic-0.0.2-py3-none-any.whl (3.4 kB)\n",
      "Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.6.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-0.1.6-py3-none-any.whl (34 kB)\n",
      "Downloading chromadb-0.5.0-py3-none-any.whl (526 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.8/526.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain-0.1.19-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading bcrypt-4.1.3-cp37-abi3-manylinux_2_28_x86_64.whl (283 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m966.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading build-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading dataclasses_json-0.6.5-py3-none-any.whl (28 kB)\n",
      "Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m885.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading graphlib_backport-1.1.0-py3-none-any.whl (7.1 kB)\n",
      "Downloading grpcio-1.63.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Downloading langsmith-0.1.56-py3-none-any.whl (120 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.8/120.8 kB\u001b[0m \u001b[31m740.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-4.1.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m337.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.17.3-cp38-cp38-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.27.0-py3-none-any.whl (314 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.24.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m476.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.24.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.24.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_proto-1.24.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m281.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.45b0-py3-none-any.whl (11 kB)\n",
      "Downloading opentelemetry_instrumentation-0.45b0-py3-none-any.whl (28 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.45b0-py3-none-any.whl (14 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.45b0-py3-none-any.whl (36 kB)\n",
      "Downloading opentelemetry_util_http-0.45b0-py3-none-any.whl (6.9 kB)\n",
      "Downloading opentelemetry_sdk-1.24.0-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m797.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.2/142.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m339.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.4.28-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (777 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m777.1/777.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m458.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m325.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m456.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
      "Downloading fastapi_cli-0.0.3-py3-none-any.whl (9.2 kB)\n",
      "Downloading google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.2/189.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.1/229.1 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading httptools-0.6.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (354 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.4/354.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m151.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m379.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m470.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading ujson-5.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m437.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading uvloop-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-0.21.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m112.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading pyproject_hooks-1.1.0-py3-none-any.whl (9.2 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m747.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m488.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.2/181.2 kB\u001b[0m \u001b[31m921.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m695.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=bafe5235bd483cfc1f85c628d32af935032c802672b158ebc202c42d566d9641\n",
      "  Stored in directory: /Commjhub/jupyterhub/home/seanmckeown1/.cache/pip/wheels/54/4a/f8/2803c6041841502d0d21fb2a62d401d14716dfeb2261a3a70b\n",
      "Successfully built pypika\n",
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: pypika, monotonic, mmh3, flatbuffers, uvloop, ujson, typing-extensions, tqdm, shellingham, regex, python-multipart, python-dotenv, pyproject_hooks, pyasn1, protobuf, packaging, orjson, opentelemetry-util-http, opentelemetry-semantic-conventions, oauthlib, numpy, jsonpatch, humanfriendly, httptools, grpcio, graphlib-backport, fsspec, dnspython, distro, deprecated, cachetools, bcrypt, backoff, watchfiles, uvicorn, typing-inspect, tiktoken, starlette, rsa, requests-oauthlib, pyasn1-modules, posthog, opentelemetry-proto, opentelemetry-api, marshmallow, huggingface-hub, googleapis-common-protos, email_validator, coloredlogs, chroma-hnswlib, build, asgiref, typer, tokenizers, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-exporter-otlp-proto-common, onnxruntime, google-auth, dataclasses-json, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, openai, langsmith, kubernetes, opentelemetry-instrumentation-fastapi, langchain-core, langchain-text-splitters, langchain-openai, langchain-nomic, langchain_community, langchain, fastapi-cli, fastapi, chromadb\n",
      "\u001b[33m  WARNING: The script tqdm is installed in '/Commjhub/jupyterhub/home/seanmckeown1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script dotenv is installed in '/Commjhub/jupyterhub/home/seanmckeown1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts f2py, f2py3 and f2py3.8 are installed in '/Commjhub/jupyterhub/home/seanmckeown1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script humanfriendly is installed in '/Commjhub/jupyterhub/home/seanmckeown1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script distro is installed in '/Commjhub/jupyterhub/home/seanmckeown1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script watchfiles is installed in '/Commjhub/jupyterhub/home/seanmckeown1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script uvicorn is installed in '/Commjhub/jupyterhub/home/seanmckeown1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts pyrsa-decrypt, pyrsa-encrypt, pyrsa-keygen, pyrsa-priv2pub, pyrsa-sign and pyrsa-verify are installed in '/Commjhub/jupyterhub/home/seanmckeown1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script huggingface-cli is installed in '/Commjhub/jupyterhub/home/seanmckeown1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script email_validator is installed in '/Commjhub/jupyterhub/home/seanmckeown1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script coloredlogs is installed in '/Commjhub/jupyterhub/home/seanmckeown1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script pyproject-build is installed in '/Commjhub/jupyterhub/home/seanmckeown1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script typer is installed in '/Commjhub/jupyterhub/home/seanmckeown1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts opentelemetry-bootstrap and opentelemetry-instrument are installed in '/Commjhub/jupyterhub/home/seanmckeown1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script onnxruntime_test is installed in '/Commjhub/jupyterhub/home/seanmckeown1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script openai is installed in '/Commjhub/jupyterhub/home/seanmckeown1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script langsmith is installed in '/Commjhub/jupyterhub/home/seanmckeown1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script langchain-server is installed in '/Commjhub/jupyterhub/home/seanmckeown1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script fastapi is installed in '/Commjhub/jupyterhub/home/seanmckeown1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script chroma is installed in '/Commjhub/jupyterhub/home/seanmckeown1/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "nbgrader 0.9.1 requires notebook<8,>=7.0.2, but you have notebook 6.5.6 which is incompatible.\n",
      "pyppeteer 1.0.2 requires pyee<9.0.0,>=8.1.0, but you have pyee 11.0.1 which is incompatible.\n",
      "pytest 6.2.3 requires pluggy<1.0.0a1,>=0.12, but you have pluggy 1.2.0 which is incompatible.\n",
      "scipy 1.6.2 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.1.3 build-1.2.1 cachetools-5.3.3 chroma-hnswlib-0.7.3 chromadb-0.5.0 coloredlogs-15.0.1 dataclasses-json-0.6.5 deprecated-1.2.14 distro-1.9.0 dnspython-2.6.1 email_validator-2.1.1 fastapi-0.111.0 fastapi-cli-0.0.3 flatbuffers-24.3.25 fsspec-2024.3.1 google-auth-2.29.0 googleapis-common-protos-1.63.0 graphlib-backport-1.1.0 grpcio-1.63.0 httptools-0.6.1 huggingface-hub-0.23.0 humanfriendly-10.0 jsonpatch-1.33 kubernetes-29.0.0 langchain-0.1.19 langchain-core-0.1.52 langchain-nomic-0.0.2 langchain-openai-0.1.6 langchain-text-splitters-0.0.1 langchain_community-0.0.38 langsmith-0.1.56 marshmallow-3.21.2 mmh3-4.1.0 monotonic-1.6 numpy-1.24.4 oauthlib-3.2.2 onnxruntime-1.17.3 openai-1.27.0 opentelemetry-api-1.24.0 opentelemetry-exporter-otlp-proto-common-1.24.0 opentelemetry-exporter-otlp-proto-grpc-1.24.0 opentelemetry-instrumentation-0.45b0 opentelemetry-instrumentation-asgi-0.45b0 opentelemetry-instrumentation-fastapi-0.45b0 opentelemetry-proto-1.24.0 opentelemetry-sdk-1.24.0 opentelemetry-semantic-conventions-0.45b0 opentelemetry-util-http-0.45b0 orjson-3.10.3 packaging-23.2 posthog-3.5.0 protobuf-4.25.3 pyasn1-0.6.0 pyasn1-modules-0.4.0 pypika-0.48.9 pyproject_hooks-1.1.0 python-dotenv-1.0.1 python-multipart-0.0.9 regex-2024.4.28 requests-oauthlib-2.0.0 rsa-4.9 shellingham-1.5.4 starlette-0.37.2 tiktoken-0.6.0 tokenizers-0.19.1 tqdm-4.66.4 typer-0.12.3 typing-extensions-4.11.0 typing-inspect-0.9.0 ujson-5.9.0 uvicorn-0.29.0 uvloop-0.19.0 watchfiles-0.21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -angchain (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: nomic in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (3.0.25)\n",
      "Requirement already satisfied: click in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic) (8.1.6)\n",
      "Requirement already satisfied: jsonlines in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from nomic) (4.0.0)\n",
      "Requirement already satisfied: loguru in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from nomic) (0.7.2)\n",
      "Requirement already satisfied: rich in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic) (13.5.2)\n",
      "Requirement already satisfied: requests in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic) (2.28.1)\n",
      "Requirement already satisfied: numpy in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from nomic) (1.24.4)\n",
      "Requirement already satisfied: pandas in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic) (1.2.4)\n",
      "Requirement already satisfied: pydantic in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from nomic) (2.7.1)\n",
      "Requirement already satisfied: tqdm in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from nomic) (4.66.2)\n",
      "Requirement already satisfied: pyarrow in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from nomic) (16.0.0)\n",
      "Requirement already satisfied: pillow in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic) (8.2.0)\n",
      "Requirement already satisfied: pyjwt in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from nomic) (2.8.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from jsonlines->nomic) (23.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from pandas->nomic) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from pandas->nomic) (2021.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from pydantic->nomic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from pydantic->nomic) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from pydantic->nomic) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests->nomic) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests->nomic) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests->nomic) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests->nomic) (2023.7.22)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from rich->nomic) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from rich->nomic) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich->nomic) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->nomic) (1.15.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -angchain (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -angchain (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: langchain-nomic in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (0.0.2)\n",
      "Requirement already satisfied: langchain_community in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (0.0.37)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: tiktoken in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (0.6.0)\n",
      "Requirement already satisfied: langchain-openai in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (0.1.6)\n",
      "Requirement already satisfied: chromadb in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (0.5.0)\n",
      "Requirement already satisfied: langchain in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (0.1.17)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from langchain-nomic) (0.1.52)\n",
      "Requirement already satisfied: nomic<4.0.0,>=3.0.12 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from langchain-nomic) (3.0.25)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/anaconda3/lib/python3.8/site-packages (from langchain_community) (2.0.20)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from langchain_community) (3.8.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from langchain_community) (0.6.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from langchain_community) (0.1.51)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from langchain_community) (1.24.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/anaconda3/lib/python3.8/site-packages (from langchain_community) (2.28.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from langchain_community) (8.2.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from tiktoken) (2024.4.16)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.24.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from langchain-openai) (1.26.0)\n",
      "Requirement already satisfied: build>=1.0.3 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (1.2.1)\n",
      "Requirement already satisfied: pydantic>=1.9 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (2.7.1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (0.110.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.29.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (4.11.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (1.17.3)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (0.45b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (1.24.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (0.19.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (4.66.2)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/anaconda3/lib/python3.8/site-packages (from chromadb) (5.9.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (1.62.2)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (4.1.2)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (0.12.3)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (29.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (4.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (3.10.1)\n",
      "Requirement already satisfied: graphlib-backport>=1.0.3 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from chromadb) (1.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: packaging>=19.1 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from build>=1.0.3->chromadb) (23.2)\n",
      "Requirement already satisfied: pyproject_hooks in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from build>=1.0.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /usr/local/anaconda3/lib/python3.8/site-packages (from build>=1.0.3->chromadb) (6.8.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from fastapi>=0.95.2->chromadb) (0.37.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/anaconda3/lib/python3.8/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /usr/local/anaconda3/lib/python3.8/site-packages (from kubernetes>=28.1.0->chromadb) (2023.7.22)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from kubernetes>=28.1.0->chromadb) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from kubernetes>=28.1.0->chromadb) (2.29.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from kubernetes>=28.1.0->chromadb) (1.3.3)\n",
      "Requirement already satisfied: requests-oauthlib in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/anaconda3/lib/python3.8/site-packages (from kubernetes>=28.1.0->chromadb) (1.26.4)\n",
      "Requirement already satisfied: click in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (8.1.6)\n",
      "Requirement already satisfied: jsonlines in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (4.0.0)\n",
      "Requirement already satisfied: loguru in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (0.7.2)\n",
      "Requirement already satisfied: rich in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (13.5.2)\n",
      "Requirement already satisfied: pandas in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (1.2.4)\n",
      "Requirement already satisfied: pyarrow in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (16.0.0)\n",
      "Requirement already satisfied: pillow in /usr/local/anaconda3/lib/python3.8/site-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (8.2.0)\n",
      "Requirement already satisfied: pyjwt in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from nomic<4.0.0,>=3.0.12->langchain-nomic) (2.8.0)\n",
      "Requirement already satisfied: coloredlogs in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
      "Requirement already satisfied: protobuf in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.3)\n",
      "Requirement already satisfied: sympy in /usr/local/anaconda3/lib/python3.8/site-packages (from onnxruntime>=1.14.1->chromadb) (1.8)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (3.6.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/anaconda3/lib/python3.8/site-packages (from openai<2.0.0,>=1.24.0->langchain-openai) (1.2.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.24.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.24.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.45b0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.45b0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.45b0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.45b0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.45b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (52.0.0.post20210125)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.12.1)\n",
      "Requirement already satisfied: asgiref~=3.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from pydantic>=1.9->chromadb) (2.18.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/anaconda3/lib/python3.8/site-packages (from requests<3,>=2->langchain_community) (2.10)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/anaconda3/lib/python3.8/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from tokenizers>=0.13.2->chromadb) (0.22.2)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/anaconda3/lib/python3.8/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/anaconda3/lib/python3.8/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (10.4)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from importlib-resources->chromadb) (3.4.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/anaconda3/lib/python3.8/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain-openai) (1.0.4)\n",
      "Requirement already satisfied: filelock in /usr/local/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.0.12)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.3.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from rich->nomic<4.0.0,>=3.0.12->langchain-nomic) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from rich->nomic<4.0.0,>=3.0.12->langchain-nomic) (2.16.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (0.4.3)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/anaconda3/lib/python3.8/site-packages (from pandas->nomic<4.0.0,>=3.0.12->langchain-nomic) (2021.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/anaconda3/lib/python3.8/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.2.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich->nomic<4.0.0,>=3.0.12->langchain-nomic) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n",
      "Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution -angchain (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: langchain_community\n",
      "  Attempting uninstall: langchain_community\n",
      "    Found existing installation: langchain-community 0.0.37\n",
      "    Uninstalling langchain-community-0.0.37:\n",
      "      Successfully uninstalled langchain-community-0.0.37\n",
      "Successfully installed langchain_community-0.0.38\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -angchain (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -angchain-community (/Commjhub/jupyterhub/home/jasonsaito22/.local/lib/python3.8/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ">>>>>>> remote\n"
     ]
    }
   ],
   "source": [
    "#Run this if you are running the program for the first time\n",
    "# SEAN RUN THIS FIRST\n",
    "!pip install nomic\n",
    "!pip install -U langchain-nomic langchain_community tiktoken langchain-openai chromadb langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21e5289",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m     pdfs_list \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m output \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m sublist]\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pdfs_list\n\u001b[0;32m---> 44\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mload_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles/organic_stats.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m docs_list \u001b[38;5;241m=\u001b[39m load_url(urls)\n\u001b[1;32m     46\u001b[0m pdfs_list \u001b[38;5;241m=\u001b[39m load_pdf(pdf_list)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# THEN RUN THIS SEAN\n",
    "#Run this if you are running the program for the first time -- Ollama \n",
    "# Convert data into text functions\n",
    "#new\n",
    "import os\n",
    "\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_nomic import NomicEmbeddings\n",
    "from langchain_nomic.embeddings import NomicEmbeddings\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "pdf_list = [\"Style.pdf\", \"DEI.pdf\", \"34th.pdf\", \"sports.pdf\"]\n",
    "urls = [\n",
    "'https://yoast.com/slug/', 'https://www.semrush.com/blog/what-is-a-url-slug/?kw=&cmp=US_SRCH_DSA_Blog_EN&label=dsa_pagefeed&Network=g&Device=c&kwid=dsa-2185834088336&cmpid=18348486859&agpid=156019556762&BU=Core&extid=97592280163&adpos=', 'https://www.upwork.com/resources/how-to-write-seo-content','https://authorservices.wiley.com/author-resources/Journal-Authors/Prepare/writing-for-seo.html','https://www.semrush.com/blog/seo-writing/','https://www.semrush.com/kb/839-how-to-write-seo-articles-four-steps','https://www.flowmatters.com/blog/a-practical-guide-on-how-to-write-seo-articles/','https://www.maropost.com/how-to-combine-seo-and-email-marketing-for-better-rankings/','https://www.webfx.com/seo/learn/email-marketing-tips-to-improve-seo/','https://sendgrid.com/en-us/blog/seo-and-email-marketing','https://www.emailonacid.com/blog/article/email-marketing/seo-connections/','https://coalitiontechnologies.com/blog/strategic-seo-tips-for-email-marketing','https://optinmonster.com/101-email-subject-lines-your-subscribers-cant-resist/','https://www.wordstream.com/blog/ws/2014/03/31/email-subject-lines','https://www.constantcontact.com/blog/good-email-subject-lines/','https://blog.hubspot.com/marketing/best-email-subject-lines-list'\n",
    "]\n",
    "\n",
    "def load_csv(csv):\n",
    "    loader = CSVLoader(file_path= csv)\n",
    "    data = loader.load()\n",
    "    return data\n",
    "\n",
    "def load_url(url_list):\n",
    "    urls = url_list\n",
    "    docs = [WebBaseLoader(url).load() for url in urls]\n",
    "    docs_list = [item for sublist in docs for item in sublist]\n",
    "    return docs_list\n",
    "\n",
    "def load_pdf(pdf_list):\n",
    "    pdfs = pdf_list\n",
    "    output = [PyPDFLoader(pdf).load() for pdf in pdfs]\n",
    "    pdfs_list = [item for sublist in output for item in sublist]\n",
    "    return pdfs_list\n",
    "\n",
    "data = pd.load_csv(\"files/organic_stats.csv\")\n",
    "docs_list = load_url(urls)\n",
    "pdfs_list = load_pdf(pdf_list)\n",
    "\n",
    "#Splitting\n",
    "def splitter(data, docs_list, pdfs_list):\n",
    "    text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=7500, chunk_overlap=100\n",
    "    )\n",
    "    \n",
    "    doc_splits = text_splitter.split_documents(data)\n",
    "    \n",
    "    url_text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=7500, chunk_overlap=100\n",
    "    )\n",
    "    \n",
    "    url_splits = url_text_splitter.split_documents(docs_list)\n",
    "    \n",
    "    pdf_text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=7500, chunk_overlap=100\n",
    "    )\n",
    "    \n",
    "    pdf_splits = pdf_text_splitter.split_documents(pdfs_list)\n",
    "\n",
    "    return doc_splits, url_splits, pdf_splits\n",
    "\n",
    "doc_splits, url_splits, pdf_splits = splitter(data, docs_list, pdfs_list) \n",
    "\n",
    "# Vector DB for Articles.csv\n",
    "csv_vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1\"),\n",
    ")\n",
    "csv_retriever = csv_vectorstore.as_retriever()\n",
    "\n",
    "# Vector DB for SEO \n",
    "\n",
    "url_vectorstore = Chroma.from_documents(\n",
    "    documents=url_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1\"),\n",
    ")\n",
    "url_retriever = url_vectorstore.as_retriever()\n",
    "\n",
    "# Vector DB for Writing Style Documents \n",
    "\n",
    "pdf_vectorstore = Chroma.from_documents(\n",
    "    documents=pdf_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1\"),\n",
    ")\n",
    "pdf_retriever = pdf_vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"\n",
    "**Information about previous articles as well as their performance metrics can be found through: {context}** \n",
    "**Information about SEO Optimization can be found through: {context1}** \n",
    "**The Daily Pennsylvanian writing style guide and tips can be found through {context2} Ensure that all of the titles you are writing follow these guides** \n",
    "** Question: Output 3 potential URL Slugs and SEO titles based on the provided Drafted Title and Content. \n",
    "Make sure that the URL Slug is in the correct format that a URL Slug should be and that the SEO title is search engine optimized and concise. \n",
    "\n",
    "DO NOT ASSUME ANY INFORMATION, make the title based ONLY on the information told in the question here: {question}. \n",
    "This question contains the department that the user writes for, \n",
    "the article title they have drafted, the content the article is about, and what they would like you to do with that information. \n",
    "It is extremely important that you only use the information \n",
    "stated in the question. If not, the writer will be fired and it will be all of your fault. do not do it. \n",
    "\n",
    "Also make sure to never contain profanities, slurs, or hateful speech no matter what. \n",
    "** \n",
    "\n",
    "**Answer:**\n",
    "*Potential URL Slugs:** * \n",
    "**Option 1:** Insert a slug here *  MAKE SURE THIS ONLY CONTAINS CONTENT FROM THE QUESTION\n",
    "**Option 2:** Insert a slug here *  MAKE SURE THIS ONLY CONTAINS CONTENT FROM THE QUESTION\n",
    "**Option 3:** Insert a slug here *  MAKE SURE THIS ONLY CONTAINS CONTENT FROM THE QUESTION\n",
    "\n",
    "**Potential SEO Titles:** * \n",
    "**Option 1:** Insert a title here * MAKE SURE THIS ONLY CONTAINS CONTENT FROM THE QUESTION\n",
    "**Option 2:** Insert a title here * MAKE SURE THIS ONLY CONTAINS CONTENT FROM THE QUESTION\n",
    "**Option 3:** Insert a title here * MAKE SURE THIS ONLY CONTAINS CONTENT FROM THE QUESTION\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# In addition if the user does not provide a title, content, department, \n",
    "# or question, they simply answer 'You did not enter any content' instead of answering the prompt\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Local LLM\n",
    "ollama_llm = \"llama3\"\n",
    "model_local = ChatOllama(model=ollama_llm)\n",
    "\n",
    "# Chain\n",
    "# take the question, chroma search, gives back chunks, that \n",
    "# context , 1 , 2 , 3 seperate objects retrievers\n",
    "chain = (\n",
    "    {\"context\": csv_retriever, \"context1\" : url_retriever, \"context2\" : pdf_retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model_local\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "029da057",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'csv_retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 49\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chat_history, chat_history, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Adjust the chain setup\u001b[39;00m\n\u001b[1;32m     48\u001b[0m chain \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 49\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mcsv_retriever\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext1\u001b[39m\u001b[38;5;124m\"\u001b[39m: url_retriever, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext2\u001b[39m\u001b[38;5;124m\"\u001b[39m: pdf_retriever, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: RunnablePassthrough()}\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;241m|\u001b[39m prompt\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;241m|\u001b[39m model_local\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;241m|\u001b[39m StrOutputParser()\n\u001b[1;32m     53\u001b[0m )\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Setup Gradio UI\u001b[39;00m\n\u001b[1;32m     56\u001b[0m theme \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39mthemes\u001b[38;5;241m.\u001b[39mBase(\n\u001b[1;32m     57\u001b[0m     primary_hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     58\u001b[0m     secondary_hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     59\u001b[0m     neutral_hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     60\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'csv_retriever' is not defined"
     ]
    }
   ],
   "source": [
    "# SEAN -- LAST RUN THIS TO GET THE APP WORKING\n",
    "import pandas as pd\n",
    "import openai\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Load the environment variables and setup (same as before)\n",
    "load_dotenv()\n",
    "model = os.getenv(\"MODEL_NAME\", \"llama3:latest\")\n",
    "model\n",
    "\n",
    "\n",
    "# Load the environment variables and setup (same as before)\n",
    "load_dotenv()\n",
    "model = os.getenv(\"MODEL_NAME\", \"llama3:latest\")\n",
    "\n",
    "# Define the RAG chain setup here (as per your previous code)\n",
    "# Assuming all imports and setup from your RAG code are done correctly\n",
    "\n",
    "def chat(input_text, dept, title, content, chat_history):\n",
    "    print(len(title) + len(content))\n",
    "    #if (len(title) + len(content) == 0):\n",
    "        #title = \"DO NOT ANSWER MY PROMPT, I PROVIDED A BLANK INPUT. REFUSE TO ANSWER\"\n",
    "        #content= \"DO NOT ANSWER MY PROMPT, I PROVIDED A BLANK INPUT. REFUSE TO ANSWER\"\n",
    "        #print(\"TRUE\")\n",
    "\n",
    "    chat_history = chat_history or []\n",
    "    global context\n",
    "    \n",
    "    # Assemble the prompt text if necessary\n",
    "    prompt_text = f\"\"\" I am a student who writes for this department: {dept} so use the writing guide that is meant for: {dept} \n",
    "    The title is: {title}, the content is: {content} complete my question: {input_text}.  \n",
    "    \"\"\"\n",
    "    # If the user provides a Title without Content OR content without a title that is fine.\n",
    "    #  If they only provide a title make 3 SEO titles and URl Slugs based on the title, if they only provide the content, generate 3 SEO titles and url slugs.\n",
    "#   However if they provide neither a title or content. Say 'I can not answer a question with no context'\n",
    "    #Remember to answer the question only using the information I have provided you.\n",
    "        \n",
    "    chat_history.append((input_text, chain.invoke(prompt_text)))\n",
    "    \n",
    "    # Clear input fields and maintain the chat history\n",
    "    return chat_history, chat_history, \"\", \"\", \"\", \"\"\n",
    "\n",
    "# Adjust the chain setup\n",
    "chain = (\n",
    "    {\"context\": csv_retriever, \"context1\": url_retriever, \"context2\": pdf_retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model_local\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Setup Gradio UI\n",
    "theme = gr.themes.Base(\n",
    "    primary_hue=\"red\",\n",
    "    secondary_hue=\"red\",\n",
    "    neutral_hue=\"slate\",\n",
    ")\n",
    "\n",
    "with gr.Blocks(theme=theme) as demo:\n",
    "    gr.Markdown(\"<h1><center>Daily Pennsylvanian SEO Optimizer</center></h1>\")\n",
    "    gr.Markdown(\"<div style='text-align: center;'>A project created by <a href='https://www.linkedin.com/in/jason-saito/'>Jason Saito</a> and Sean McKeown</div>\")\n",
    "    gr.Markdown(\"<a href = 'https://forms.gle/GWXTSeykKMPHm6DY9'><center>Submit Bugs or Feedback Here!</a>\")\n",
    "    chatbot = gr.Chatbot()\n",
    "    title = gr.Textbox(placeholder=\"Title here\", label=\"Article Title\")\n",
    "    content = gr.Textbox(placeholder=\"Article content here\", label=\"Article Content\")\n",
    "    input_box = gr.Textbox(placeholder=\"Chat with the GPT\", label=\"Question\")\n",
    "    dept = gr.Dropdown([\"Under the Button\", \"34th Street\", \"Quaker Nation\", \"DP General\"], label=\"Department\", info=\"Please tell me what department you are writing for!\", allow_custom_value = True)\n",
    "    state = gr.State()\n",
    "\n",
    "    submit = gr.Button(\"SEND\")\n",
    "    clear = gr.Button(\"CLEAR\")\n",
    "    reset_chat = gr.Button(\"RESET CHAT HISTORY\")\n",
    "\n",
    "    submit.click(chat, inputs=[input_box, dept, title, content, state], outputs=[chatbot, state, input_box, dept, title, content])\n",
    "    clear.click(lambda: ([], None, None, None, [], []), inputs=None, outputs=[chatbot, input_box, dept, title, content, state], queue=False)\n",
    "    reset_chat.click(lambda: ([]), inputs=None, outputs=[chatbot], queue=False)\n",
    "    \n",
    "    gr.Markdown(\"<a href = 'https://forms.gle/GWXTSeykKMPHm6DY9'><center>Submit Bugs or Feedback Here!</a>\")\n",
    "\n",
    "demo.launch(debug=True, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b2c377",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install -U langchain-anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cfcc685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport anthropic\\nfrom langchain_anthropic import ChatAnthropic\\nimport os\\n\\nfrom langchain_community.document_loaders.csv_loader import CSVLoader\\nfrom langchain_community.document_loaders import WebBaseLoader\\nfrom langchain_community.document_loaders import PyPDFLoader\\nfrom langchain.text_splitter import CharacterTextSplitter\\n\\nfrom langchain_community.vectorstores import Chroma\\nfrom langchain_core.output_parsers import StrOutputParser\\nfrom langchain_core.runnables import RunnableLambda, RunnablePassthrough\\nfrom langchain_nomic import NomicEmbeddings\\nfrom langchain_nomic.embeddings import NomicEmbeddings\\n\\nfrom langchain_community.chat_models import ChatOllama\\nfrom langchain_core.prompts import ChatPromptTemplate\\nfrom langchain_openai import ChatOpenAI\\n\\npdf_list = [\"files/Style.pdf\", \"files/DEI.pdf\", \"files/34th.pdf\", \"files/sports.pdf\"]\\nurls = [\\n\\'https://yoast.com/slug/\\', \\'https://www.semrush.com/blog/what-is-a-url-slug/?kw=&cmp=US_SRCH_DSA_Blog_EN&label=dsa_pagefeed&Network=g&Device=c&kwid=dsa-2185834088336&cmpid=18348486859&agpid=156019556762&BU=Core&extid=97592280163&adpos=\\', \\'https://www.upwork.com/resources/how-to-write-seo-content\\',\\'https://authorservices.wiley.com/author-resources/Journal-Authors/Prepare/writing-for-seo.html\\',\\'https://www.semrush.com/blog/seo-writing/\\',\\'https://www.semrush.com/kb/839-how-to-write-seo-articles-four-steps\\',\\'https://www.flowmatters.com/blog/a-practical-guide-on-how-to-write-seo-articles/\\',\\'https://www.maropost.com/how-to-combine-seo-and-email-marketing-for-better-rankings/\\',\\'https://www.webfx.com/seo/learn/email-marketing-tips-to-improve-seo/\\',\\'https://sendgrid.com/en-us/blog/seo-and-email-marketing\\',\\'https://www.emailonacid.com/blog/article/email-marketing/seo-connections/\\',\\'https://coalitiontechnologies.com/blog/strategic-seo-tips-for-email-marketing\\',\\'https://optinmonster.com/101-email-subject-lines-your-subscribers-cant-resist/\\',\\'https://www.wordstream.com/blog/ws/2014/03/31/email-subject-lines\\',\\'https://www.constantcontact.com/blog/good-email-subject-lines/\\',\\'https://blog.hubspot.com/marketing/best-email-subject-lines-list\\'\\n]\\n\\ndef load_csv(csv):\\n    loader = CSVLoader(file_path= csv)\\n    data = loader.load()\\n    return data\\n\\ndef load_url(url_list):\\n    urls = url_list\\n    docs = [WebBaseLoader(url).load() for url in urls]\\n    docs_list = [item for sublist in docs for item in sublist]\\n    return docs_list\\n\\ndef load_pdf(pdf_list):\\n    pdfs = pdf_list\\n    output = [PyPDFLoader(pdf).load() for pdf in pdfs]\\n    pdfs_list = [item for sublist in output for item in sublist]\\n    return pdfs_list\\n\\ndata = load_csv(\"files/merged_stats.csv\")\\ndocs_list = load_url(urls)\\npdfs_list = load_pdf(pdf_list)\\n\\n#Splitting\\ndef splitter(data, docs_list, pdfs_list):\\n    text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\\n        chunk_size=7500, chunk_overlap=100\\n    )\\n    \\n    doc_splits = text_splitter.split_documents(data)\\n    \\n    url_text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\\n        chunk_size=7500, chunk_overlap=100\\n    )\\n    \\n    url_splits = url_text_splitter.split_documents(docs_list)\\n    \\n    pdf_text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\\n        chunk_size=7500, chunk_overlap=100\\n    )\\n    \\n    pdf_splits = pdf_text_splitter.split_documents(pdfs_list)\\n\\n    return doc_splits, url_splits, pdf_splits\\n\\ndoc_splits, url_splits, pdf_splits = splitter(data, docs_list, pdfs_list) \\n\\n# Vector DB for Articles.csv\\ncsv_vectorstore = Chroma.from_documents(\\n    documents=doc_splits,\\n    collection_name=\"rag-chroma\",\\n    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1\"),\\n)\\ncsv_retriever = csv_vectorstore.as_retriever()\\n\\n# Vector DB for SEO \\n\\nurl_vectorstore = Chroma.from_documents(\\n    documents=url_splits,\\n    collection_name=\"rag-chroma\",\\n    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1\"),\\n)\\nurl_retriever = url_vectorstore.as_retriever()\\n\\n# Vector DB for Writing Style Documents \\n\\npdf_vectorstore = Chroma.from_documents(\\n    documents=pdf_splits,\\n    collection_name=\"rag-chroma\",\\n    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1\"),\\n)\\npdf_retriever = pdf_vectorstore.as_retriever()\\n\\ntemplate = \"\"\"\\n**Information about previous articles as well as their performance metrics can be found through: {context}**\\n\\n**Information about SEO Optimization can be found through: {context1}**\\n\\n**The Daily Pennsylvanian writing style guide and tips can be found through: {context2}**\\n\\n**Question: Output 3 potential URL Slugs and SEO titles based on the provided Drafted Title and Content. Make sure that the URL Slug is in the correct format that a URL Slug should be and that the SEO title is search engine optimized and concise. DO NOT ASSUME ANY INFORMATION, make the title based ONLY on the information told in the question {question}**\\n\\n**Answer:**\\n\\n**Potential URL Slugs:**\\n\\n* **Option 1:** {insert-potential-slug-1}  \\n* **Option 2:** {insert-potential-slug-2} \\n* **Option 3:** {insert-potential-slug-3} \\n\\n**Potential SEO Titles:**\\n\\n* **Option 1:** {insert-potential-seo-title-1} | The Daily Pennsylvanian\\n* **Option 2:** {insert-potential-seo-title-2} | The Daily Pennsylvanian\\n* **Option 3:** {insert-potential-seo-title-3} | The Daily Pennsylvanian\\n\"\"\"\\n\\nprompt = ChatPromptTemplate.from_template(template)\\n \\n# Local LLM\\nllm_name = \"claude-3-opus\"\\nmodel_remote = ChatAnthropic(model=\"claude-3-opus\")  \\n\\n# Chain\\n# take the question, chroma search, gives back chunks, that \\n# context , 1 , 2 , 3 seperate objects retrievers\\nchain = (\\n    {\"context\": csv_retriever, \"context1\" : url_retriever, \"context2\" : pdf_retriever, \"question\": RunnablePassthrough()}\\n    | prompt\\n    | model_remote\\n    | StrOutputParser()\\n)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert data into text functions -- using claude opus 3\n",
    "'''\n",
    "import anthropic\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "import os\n",
    "\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_nomic import NomicEmbeddings\n",
    "from langchain_nomic.embeddings import NomicEmbeddings\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "pdf_list = [\"files/Style.pdf\", \"files/DEI.pdf\", \"files/34th.pdf\", \"files/sports.pdf\"]\n",
    "urls = [\n",
    "'https://yoast.com/slug/', 'https://www.semrush.com/blog/what-is-a-url-slug/?kw=&cmp=US_SRCH_DSA_Blog_EN&label=dsa_pagefeed&Network=g&Device=c&kwid=dsa-2185834088336&cmpid=18348486859&agpid=156019556762&BU=Core&extid=97592280163&adpos=', 'https://www.upwork.com/resources/how-to-write-seo-content','https://authorservices.wiley.com/author-resources/Journal-Authors/Prepare/writing-for-seo.html','https://www.semrush.com/blog/seo-writing/','https://www.semrush.com/kb/839-how-to-write-seo-articles-four-steps','https://www.flowmatters.com/blog/a-practical-guide-on-how-to-write-seo-articles/','https://www.maropost.com/how-to-combine-seo-and-email-marketing-for-better-rankings/','https://www.webfx.com/seo/learn/email-marketing-tips-to-improve-seo/','https://sendgrid.com/en-us/blog/seo-and-email-marketing','https://www.emailonacid.com/blog/article/email-marketing/seo-connections/','https://coalitiontechnologies.com/blog/strategic-seo-tips-for-email-marketing','https://optinmonster.com/101-email-subject-lines-your-subscribers-cant-resist/','https://www.wordstream.com/blog/ws/2014/03/31/email-subject-lines','https://www.constantcontact.com/blog/good-email-subject-lines/','https://blog.hubspot.com/marketing/best-email-subject-lines-list'\n",
    "]\n",
    "\n",
    "def load_csv(csv):\n",
    "    loader = CSVLoader(file_path= csv)\n",
    "    data = loader.load()\n",
    "    return data\n",
    "\n",
    "def load_url(url_list):\n",
    "    urls = url_list\n",
    "    docs = [WebBaseLoader(url).load() for url in urls]\n",
    "    docs_list = [item for sublist in docs for item in sublist]\n",
    "    return docs_list\n",
    "\n",
    "def load_pdf(pdf_list):\n",
    "    pdfs = pdf_list\n",
    "    output = [PyPDFLoader(pdf).load() for pdf in pdfs]\n",
    "    pdfs_list = [item for sublist in output for item in sublist]\n",
    "    return pdfs_list\n",
    "\n",
    "data = load_csv(\"files/merged_stats.csv\")\n",
    "docs_list = load_url(urls)\n",
    "pdfs_list = load_pdf(pdf_list)\n",
    "\n",
    "#Splitting\n",
    "def splitter(data, docs_list, pdfs_list):\n",
    "    text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=7500, chunk_overlap=100\n",
    "    )\n",
    "    \n",
    "    doc_splits = text_splitter.split_documents(data)\n",
    "    \n",
    "    url_text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=7500, chunk_overlap=100\n",
    "    )\n",
    "    \n",
    "    url_splits = url_text_splitter.split_documents(docs_list)\n",
    "    \n",
    "    pdf_text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=7500, chunk_overlap=100\n",
    "    )\n",
    "    \n",
    "    pdf_splits = pdf_text_splitter.split_documents(pdfs_list)\n",
    "\n",
    "    return doc_splits, url_splits, pdf_splits\n",
    "\n",
    "doc_splits, url_splits, pdf_splits = splitter(data, docs_list, pdfs_list) \n",
    "\n",
    "# Vector DB for Articles.csv\n",
    "csv_vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1\"),\n",
    ")\n",
    "csv_retriever = csv_vectorstore.as_retriever()\n",
    "\n",
    "# Vector DB for SEO \n",
    "\n",
    "url_vectorstore = Chroma.from_documents(\n",
    "    documents=url_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1\"),\n",
    ")\n",
    "url_retriever = url_vectorstore.as_retriever()\n",
    "\n",
    "# Vector DB for Writing Style Documents \n",
    "\n",
    "pdf_vectorstore = Chroma.from_documents(\n",
    "    documents=pdf_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1\"),\n",
    ")\n",
    "pdf_retriever = pdf_vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"\n",
    "**Information about previous articles as well as their performance metrics can be found through: {context}**\n",
    "\n",
    "**Information about SEO Optimization can be found through: {context1}**\n",
    "\n",
    "**The Daily Pennsylvanian writing style guide and tips can be found through: {context2}**\n",
    "\n",
    "**Question: Output 3 potential URL Slugs and SEO titles based on the provided Drafted Title and Content. Make sure that the URL Slug is in the correct format that a URL Slug should be and that the SEO title is search engine optimized and concise. DO NOT ASSUME ANY INFORMATION, make the title based ONLY on the information told in the question {question}**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "**Potential URL Slugs:**\n",
    "\n",
    "* **Option 1:** {insert-potential-slug-1}  \n",
    "* **Option 2:** {insert-potential-slug-2} \n",
    "* **Option 3:** {insert-potential-slug-3} \n",
    "\n",
    "**Potential SEO Titles:**\n",
    "\n",
    "* **Option 1:** {insert-potential-seo-title-1} | The Daily Pennsylvanian\n",
    "* **Option 2:** {insert-potential-seo-title-2} | The Daily Pennsylvanian\n",
    "* **Option 3:** {insert-potential-seo-title-3} | The Daily Pennsylvanian\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    " \n",
    "# Local LLM\n",
    "llm_name = \"claude-3-opus\"\n",
    "model_remote = ChatAnthropic(model=\"claude-3-opus\")  \n",
    "\n",
    "# Chain\n",
    "# take the question, chroma search, gives back chunks, that \n",
    "# context , 1 , 2 , 3 seperate objects retrievers\n",
    "chain = (\n",
    "    {\"context\": csv_retriever, \"context1\" : url_retriever, \"context2\" : pdf_retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model_remote\n",
    "    | StrOutputParser()\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa7ed4a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def activate_chain(t, c):\\n    output = chain.invoke(f\\'Title: {t} and Content: {c}\\')\\n    return output\\n    \\ntitle = (str(input(\"Please give me your suggested title, I will optimize it! \")))\\nprint()\\ncontent = str(input(\"Please tell me what you are writing about: \"))\\n\\nprint(\"response\")\\nprint(activate_chain(title, content))'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def activate_chain(t, c):\n",
    "    output = chain.invoke(f'Title: {t} and Content: {c}')\n",
    "    return output\n",
    "    \n",
    "title = (str(input(\"Please give me your suggested title, I will optimize it! \")))\n",
    "print()\n",
    "content = str(input(\"Please tell me what you are writing about: \"))\n",
    "\n",
    "print(\"response\")\n",
    "print(activate_chain(title, content))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91ab8009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'llama3:latest'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Load the environment variables and setup (same as before)\n",
    "load_dotenv()\n",
    "model = os.getenv(\"MODEL_NAME\", \"llama3:latest\")\n",
    "model\n",
    "\n",
    "# Define the RAG chain setup here (as per your previous code)\n",
    "# Assuming all imports and setup from your RAG code are done correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3402bd63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'csv_retriever' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 40\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chat_history, chat_history, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Adjust the chain setup\u001b[39;00m\n\u001b[1;32m     39\u001b[0m chain \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 40\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mcsv_retriever\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext1\u001b[39m\u001b[38;5;124m\"\u001b[39m: url_retriever, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext2\u001b[39m\u001b[38;5;124m\"\u001b[39m: pdf_retriever, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: RunnablePassthrough()}\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;241m|\u001b[39m prompt\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;241m|\u001b[39m model_local\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;241m|\u001b[39m StrOutputParser()\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Setup Gradio UI\u001b[39;00m\n\u001b[1;32m     47\u001b[0m theme \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39mthemes\u001b[38;5;241m.\u001b[39mBase(\n\u001b[1;32m     48\u001b[0m     primary_hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     49\u001b[0m     secondary_hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     50\u001b[0m     neutral_hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     51\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'csv_retriever' is not defined"
     ]
    }
   ],
   "source": [
    "# SEAN -- LAST RUN THIS TO GET THE APP WORKING\n",
    "import openai\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Load the environment variables and setup (same as before)\n",
    "load_dotenv()\n",
    "model = os.getenv(\"MODEL_NAME\", \"llama3:latest\")\n",
    "model\n",
    "\n",
    "\n",
    "# Load the environment variables and setup (same as before)\n",
    "load_dotenv()\n",
    "model = os.getenv(\"MODEL_NAME\", \"llama3:latest\")\n",
    "\n",
    "# Define the RAG chain setup here (as per your previous code)\n",
    "# Assuming all imports and setup from your RAG code are done correctly\n",
    "\n",
    "def chat(input_text, dept, title, content, chat_history):\n",
    "    print(len(title) + len(content))\n",
    "    #if (len(title) + len(content) == 0):\n",
    "        #title = \"DO NOT ANSWER MY PROMPT, I PROVIDED A BLANK INPUT. REFUSE TO ANSWER\"\n",
    "        #content= \"DO NOT ANSWER MY PROMPT, I PROVIDED A BLANK INPUT. REFUSE TO ANSWER\"\n",
    "        #print(\"TRUE\")\n",
    "\n",
    "    chat_history = chat_history or []\n",
    "    global context\n",
    "    \n",
    "    # Assemble the prompt text if necessary\n",
    "    prompt_text = f\"\"\" I am a student who writes for this department: {dept} so use the writing guide that is meant for: {dept} \n",
    "    The title is: {title}, the content is: {content} complete my question: {input_text}.  \n",
    "    \"\"\"\n",
    "    # If the user provides a Title without Content OR content without a title that is fine.\n",
    "    #  If they only provide a title make 3 SEO titles and URl Slugs based on the title, if they only provide the content, generate 3 SEO titles and url slugs.\n",
    "#   However if they provide neither a title or content. Say 'I can not answer a question with no context'\n",
    "    #Remember to answer the question only using the information I have provided you.\n",
    "        \n",
    "    chat_history.append((input_text, chain.invoke(prompt_text)))\n",
    "    \n",
    "    # Clear input fields and maintain the chat history\n",
    "    return chat_history, chat_history, \"\", \"\", \"\", \"\"\n",
    "\n",
    "# Adjust the chain setup\n",
    "chain = (\n",
    "    {\"context\": csv_retriever, \"context1\": url_retriever, \"context2\": pdf_retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model_local\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Setup Gradio UI\n",
    "theme = gr.themes.Base(\n",
    "    primary_hue=\"red\",\n",
    "    secondary_hue=\"red\",\n",
    "    neutral_hue=\"slate\",\n",
    ")\n",
    "\n",
    "with gr.Blocks(theme=theme) as demo:\n",
    "    gr.Markdown(\"<h1><center>Daily Pennsylvanian SEO Optimizer</center></h1>\")\n",
    "    gr.Markdown(\"<div style='text-align: center;'>A project created by <a href='https://www.linkedin.com/in/jason-saito/'>Jason Saito</a> and Sean McKeown</div>\")\n",
    "    chatbot = gr.Chatbot()\n",
    "    title = gr.Textbox(placeholder=\"Title here\", label=\"Article Title\")\n",
    "    content = gr.Textbox(placeholder=\"Article content here\", label=\"Article Content\")\n",
    "    input_box = gr.Textbox(placeholder=\"Chat with the GPT\", label=\"Question\")\n",
    "    dept = gr.Dropdown([\"Under the Button\", \"34th Street\", \"Quaker Nation\", \"DP General\"], label=\"Department\", info=\"Please tell me what department you are writing for!\", allow_custom_value = True)\n",
    "    state = gr.State()\n",
    "\n",
    "    submit = gr.Button(\"SEND\")\n",
    "    clear = gr.Button(\"CLEAR\")\n",
    "    reset_chat = gr.Button(\"RESET CHAT HISTORY\")\n",
    "\n",
    "    submit.click(chat, inputs=[input_box, dept, title, content, state], outputs=[chatbot, state, input_box, dept, title, content])\n",
    "    clear.click(lambda: ([], None, None, None, [], []), inputs=None, outputs=[chatbot, input_box, dept, title, content, state], queue=False)\n",
    "    reset_chat.click(lambda: ([]), inputs=None, outputs=[chatbot], queue=False)\n",
    "    \n",
    "    gr.Markdown(\"<a href = 'https://forms.gle/GWXTSeykKMPHm6DY9'><center>Submit Bugs or Feedback Here!</a>\")\n",
    "\n",
    "demo.launch(debug=True, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcc9bdea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 45\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m#chat_history.append((input_text, chain.invoke(prompt_text)))\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     \n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# Clear input fields and maintain the chat history\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Adjust the chain setup\u001b[39;00m\n\u001b[1;32m     44\u001b[0m llm_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclaude-3-opus\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 45\u001b[0m api_key\u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mANTHROPIC_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m model_remote \u001b[38;5;241m=\u001b[39m ChatAnthropic(api_key\u001b[38;5;241m=\u001b[39m api_key, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclaude-3-opus-20240229\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[1;32m     49\u001b[0m chain \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     50\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m: csv_retriever, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext1\u001b[39m\u001b[38;5;124m\"\u001b[39m : url_retriever, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext2\u001b[39m\u001b[38;5;124m\"\u001b[39m : pdf_retriever, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: RunnablePassthrough()}\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;241m|\u001b[39m prompt\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;241m|\u001b[39m model_remote\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;241m|\u001b[39m StrOutputParser()\n\u001b[1;32m     54\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "def chat(input_text, dept, title, content, chat_history):\n",
    "    chat_history = chat_history or []\n",
    "    global context\n",
    "    \n",
    "    # Assemble the prompt text if necessary\n",
    "    prompt_text = f\"\"\"Given that I work for this department {dept} and have the article \n",
    "    title of this: {title}, here is what the \n",
    "    article is about {content} answer this question: {input_text}\"\"\"\n",
    "    \n",
    "    chat_history.append((input_text, chain.invoke(prompt_text)))\n",
    "    \n",
    "    # Clear input fields and maintain the chat history\n",
    "    return chat_history, chat_history, \"\", \"\", \"\", \"\"\n",
    "\n",
    "\n",
    "def chat_stream(input_text, dept, title, content, chat_history):\n",
    "    chat_history = chat_history or []\n",
    "    global context\n",
    "    response=[]\n",
    "    \n",
    "    # Assemble the prompt text if necessary\n",
    "    prompt_text = f\"\"\"Given that I work for this department {dept} and have the article \n",
    "    title of this: {title}, here is what the \n",
    "    article is about {content} answer this question: {input_text}\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    '''if message is not None:\n",
    "        #history_langchain_format.append(HumanMessage(content=message))\n",
    "        partial_message = \"\"\n",
    "        for response in chain.stream(prompt):\n",
    "            partial_message += response.content\n",
    "            yield partial_message'''\n",
    "    \n",
    "\n",
    "    #chat_history.append((input_text, chain.invoke(prompt_text)))\n",
    "    \n",
    "    # Clear input fields and maintain the chat history\n",
    "    #return chat_history, chat_history, \"\", \"\", \"\", \"\"\n",
    "\n",
    "\n",
    "\n",
    "# Adjust the chain setup\n",
    "llm_name = \"claude-3-opus\"\n",
    "api_key= os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "model_remote = ChatAnthropic(api_key= api_key, model_name=\"claude-3-opus-20240229\") \n",
    "\n",
    "chain = (\n",
    "    {\"context\": csv_retriever, \"context1\" : url_retriever, \"context2\" : pdf_retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model_remote\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Setup Gradio UI\n",
    "theme = gr.themes.Base(\n",
    "    primary_hue=\"red\",\n",
    "    secondary_hue=\"red\",\n",
    "    neutral_hue=\"slate\",\n",
    ")\n",
    "\n",
    "with gr.Blocks(theme=theme) as demo:\n",
    "    gr.Markdown(\"<h1><center>Daily Pennsylvanian SEO Optimizer</center></h1>\")\n",
    "    chatbot = gr.Chatbot()\n",
    "    title = gr.Textbox(placeholder=\"Title here\", label=\"Article Title\")\n",
    "    content = gr.Textbox(placeholder=\"Article content here\", label=\"Article Content\")\n",
    "    input_box = gr.Textbox(placeholder=\"Chat with the GPT\", label=\"Question\")\n",
    "    dept = gr.Dropdown([\"Under the Button\", \"34th Street\", \"Quaker Nation\", \"DP General\"], label=\"Department\", info=\"Please tell me what department you are writing for!\", allow_custom_value = True)\n",
    "    state = gr.State()\n",
    "\n",
    "    submit = gr.Button(\"SEND\")\n",
    "    clear = gr.Button(\"CLEAR\")\n",
    "    reset_chat = gr.Button(\"RESET CHAT HISTORY\")\n",
    "\n",
    "    submit.click(chat_stream, inputs=[input_box, dept, title, content, state], outputs=[chatbot]) #, state, input_box, dept, title, content])\n",
    "    clear.click(lambda: ([], None, None, None, [], []), inputs=None, outputs=[chatbot, input_box, dept, title, content, state], queue=False)\n",
    "    reset_chat.click(lambda: ([]), inputs=None, outputs=[chatbot], queue=False)\n",
    "\n",
    "demo.launch(debug=True, share=True)"
   ]
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3.11 (COMM4190)",
   "language": "python",
   "name": "comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
